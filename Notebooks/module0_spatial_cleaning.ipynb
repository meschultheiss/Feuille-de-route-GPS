{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5003603-5904-41a6-bd71-91cce763d32e",
   "metadata": {},
   "source": [
    "# Readme Panel Lémanique\n",
    "Ce notebook reprend les données brutes GPS 2023 du Panel Lémanique et en fourni une première phase de nettoyage et de filtrage des données. A savoir deux niveau de \"perte de signal\" identifiés par les colonnes 'low_quality_legs_1' (env. 5% de traces éliminées) et 'low_quality_legs_2' (env. 7% de traces éliminées).\n",
    "## GPS tracking\n",
    "Les données GPS sont issues de la phase de collecte sur 21 jours au printemps 2023.\n",
    "## Fichiers de base utilisés\n",
    "- Brut: gps_panel_lemanique_by_motion_tag.csv\n",
    "- Lines: lines.geojson, fichié fourni par Elisa Tirindelli le 17/08/23 --> renommé legs.geojson\n",
    "- Points: points.geojson, fichié fourni par Elisa Tirindelli le 17/08/23 --> renommé staypoints.geojson\n",
    "- Fichiers de raccordement: Localisation_domicile.csv par Florian Masse (trouvé sur le serveur LASUR)\n",
    "- Géoinformation: Verkehrszonen_Schweiz_NPVM_2017.shp, Zone de Trafic du modèle voyageur suisse\n",
    "- Questionnaire: EPFL_vague1_v4.csv, fourni par Alexis Gumy le 21/09/23\n",
    "## Nettoyage par Elisa\n",
    "- élimination des déplacements qui se répètent pour chaque personne plus qu’une fois (pour l'elimiation de bias dans des données)\n",
    "- élimination des déplacements “triangles” (déplacement qui revient au même endroit plusieurs fois), les déplacements qui partent (ou arrivent) deux fois du (au) même endroits\n",
    "- élimination des trajets (dans un même déplacement) qui partent plus tard qu’une demi heure après le trajet avant\n",
    "- corriger les déplacements qui contienne plus qu’un trajet sur la même ligne (regrouper tous les trajets consecutives sur une ligne dans un seul trajet)\n",
    "- corriger le temps de trajet (aussi la distance) du déplacement (les recalculer pour tenir en compte le trajets qui ont été éliminé)\n",
    "- réfléchir sur les déplacements qui comprennent plus que 3/4 trajets TP (assez improbable)\n",
    "## Nettoyage complémentaires par Marc-Edouard (voir dans le notebook ci-dessous)\n",
    "- Enlever les étapes avec perte de signal (i.e. discontinuous legs) -> perte de 530 traces / 669808\n",
    "- Segmentation des données par Canton pour faciliter la manipulation des données\n",
    "- Gérer les legs non géolocalisés (beeline between OD)\n",
    "- Calcul du nombre d'observation moyen par répondant.e\n",
    "\n",
    "## Spotted issues\n",
    "- 'CH14886', 'CH15539' are duplicates in the vague1_v4 file\n",
    "- 'FR13508', 'CH8035', 'CH14765' are not in the vague1_v4 file but appear in the gps file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d69600-5761-467c-a60d-2edc1dff9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "from shapely import geometry, ops\n",
    "from shapely.geometry import MultiLineString, LineString, Point\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "import xyt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe421f-f4dd-4786-9ba8-65cb233c6cf0",
   "metadata": {},
   "source": [
    "## Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469aea0b-992c-432d-90ec-5a0dd63a163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define the CRS you want to use (e.g., EPSG:4326 for WGS84)\n",
    "target_crs = 'EPSG:4326'\n",
    "\n",
    "# load geo data\n",
    "legs = pd.read_pickle('../Data/dumps_motiontag/storyline_formated/legs.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2580044f-2a41-422d-b356-3b14647bcacb",
   "metadata": {},
   "source": [
    "#### Vérifier si nous avons que des linestrings\n",
    "Si non, se réferer au notebook `module0_parsestoryline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55d4e7-6827-49f0-95fd-d9cb2fe42975",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs.geometry.geom_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b435b-34af-454e-967a-9eaed2a16456",
   "metadata": {},
   "source": [
    "## Nettoyage des pertes de signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac136e85-f1c4-47ee-9f21-ced672c44645",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE THE MODE SPLIT TO APPLY DIFFERENT THRESHOLDS TO EACH MODE\n",
    "\n",
    "# We propose two level of threshold to be more or less selective in the thresholds (e.g., road_psr_1 and road_psr_2, etc)\n",
    "\n",
    "mode_road = ['Mode::Car', 'Mode::Motorbike', 'Mode::Bus', 'Mode::Tram', 'Mode::Subway', 'Mode::KickScooter', 'Mode::LightRail', 'Mode::Other','Mode::TaxiUber', 'Mode::Carsharing', 'Mode::Ecar']\n",
    "road_psa_1 = 8000\n",
    "road_psr_1 = 0.8\n",
    "road_psa_2 = 5000\n",
    "road_psr_2 = 0.6\n",
    "\n",
    "mode_rail = ['Mode::Train','Mode::RegionalTrain']\n",
    "rail_psa_1 = 100000\n",
    "rail_psr_1 = 0.65\n",
    "rail_psa_2 = 85000\n",
    "rail_psr_2 = 0.50\n",
    "\n",
    "mode_active = ['Mode::Bicycle', 'Mode::Ebicycle', 'Mode::Walk']\n",
    "active_psa_1 = 800\n",
    "active_psr_1 = 0.8\n",
    "active_psa_2 = 750\n",
    "active_psr_2 = 0.7\n",
    "\n",
    "mode_plane_boat = ['Mode::Boat', 'Mode::Airplane']\n",
    "plane_boat_psa_1 = 0\n",
    "plane_boat_psr_1 = 0\n",
    "plane_boat_psa_2 = 0\n",
    "plane_boat_psr_2 = 0\n",
    "\n",
    "# Create dictionaries for each category\n",
    "road_category_1 = {'modes': mode_road, 'psa': road_psa_1, 'psr': road_psr_1}\n",
    "rail_category_1 = {'modes': mode_rail, 'psa': rail_psa_1, 'psr': rail_psr_1}\n",
    "active_category_1 = {'modes': mode_active, 'psa': active_psa_1, 'psr': active_psr_1}\n",
    "plane_boat_category_1 = {'modes': mode_plane_boat, 'psa': plane_boat_psa_1, 'psr': plane_boat_psr_1}\n",
    "\n",
    "road_category_2 = {'modes': mode_road, 'psa': road_psa_2, 'psr': road_psr_2}\n",
    "rail_category_2 = {'modes': mode_rail, 'psa': rail_psa_2, 'psr': rail_psr_2}\n",
    "active_category_2 = {'modes': mode_active, 'psa': active_psa_2, 'psr': active_psr_2}\n",
    "plane_boat_category_2 = {'modes': mode_plane_boat, 'psa': plane_boat_psa_2, 'psr': plane_boat_psr_2}\n",
    "\n",
    "# Create a dictionary to store the categories\n",
    "signal_categories = [{\n",
    "    'road': road_category_1,\n",
    "    'rail': rail_category_1,\n",
    "    'mode_active': active_category_1,\n",
    "    'mode_plane_boat': plane_boat_category_1},{\n",
    "    'road': road_category_2,\n",
    "    'rail': rail_category_2,\n",
    "    'mode_active': active_category_2,\n",
    "    'mode_plane_boat': plane_boat_category_2}]\n",
    "\n",
    "# Example: Accessing values for the 'road' category\n",
    "print(\"Category: road\")\n",
    "print(\"Modes:\", signal_categories[1]['road']['modes'])\n",
    "print(\"PSA:\", signal_categories[1]['road']['psa'])\n",
    "print(\"PSR:\", signal_categories[1]['road']['psr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82786a8d-553d-45cf-815b-b51332d04115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the maximum distance in meters between two points in a LineString\n",
    "def calculate_max_distance(line):\n",
    "    # Extract the coordinates of the LineString into a list of points\n",
    "    points = list(line.coords)\n",
    "    \n",
    "    # Initialize a list to store the distances between consecutive points\n",
    "    distances = []\n",
    "\n",
    "    # Iterate through the points to calculate and store the distances\n",
    "    for i in range(len(points) - 1):\n",
    "        point1 = Point(points[i])\n",
    "        point2 = Point(points[i + 1])\n",
    "        distance = point1.distance(point2)\n",
    "        distances.append(distance)\n",
    "\n",
    "    # Find the maximum distance from the list of distances\n",
    "    max_distance = max(distances)\n",
    "    \n",
    "    return max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4586063-c914-4770-b95c-b912abea0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## !!! This one takes a while (around 60min) !\n",
    "legs_ = legs.to_crs(crs=\"EPSG:2056\").copy()\n",
    "# Apply the calculate_max_distance function to the GeoSeries and store the result in a new column\n",
    "legs_['max_signlalloss_meters'] = legs_.apply(lambda row: calculate_max_distance(row['geometry']), axis=1)\n",
    "\n",
    "# Compute the lenght of each leg\n",
    "legs_['length_leg'] = legs_['geometry'].apply(lambda geom: geom.length)\n",
    "\n",
    "# Compute the relative signal loss\n",
    "legs_['rel_max_signalloss'] = legs_['max_signlalloss_meters'].div(legs_['length_leg'])\n",
    "\n",
    "# Save as temp file in case of crash\n",
    "legs_.to_pickle(\"../Data/temp_files/legs_rel_max_signal_loss.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bba8f0-7399-4be1-a872-43610f9cb817",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##TRY this parralilazation approach instead ?\n",
    "#import dask.dataframe as dd\n",
    "#\n",
    "#legs_ = legs.to_crs(crs=\"EPSG:2056\").copy()\n",
    "## Convert GeoPandas dataframe to Dask GeoDataFrame\n",
    "#legs_dask = dd.from_pandas(legs_, npartitions=7)\n",
    "#\n",
    "## Define a function to calculate max distance\n",
    "#def calculate_max_distance_dask(geom):\n",
    "#    # Your calculate_max_distance function here\n",
    "#    pass\n",
    "#\n",
    "## Apply the function to the Dask GeoDataFrame\n",
    "#legs_dask['max_signlalloss_meters'] = legs_dask['geometry'].apply(calculate_max_distance_dask, meta=('geometry', 'float'))\n",
    "#legs_dask['length_leg'] = legs_dask['geometry'].apply(lambda geom: geom.length, meta=('geometry', 'float'))\n",
    "#legs_dask['rel_max_signalloss'] = legs_dask['max_signlalloss_meters'] / legs_dask['length_leg']\n",
    "#\n",
    "## Compute the results\n",
    "#legs_ = legs_dask.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04c5e0f-e75b-429f-8e59-7507d8695987",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Add a column to flag the legs that we want to filter out\n",
    "legs_['low_quality_legs_1'] = 0\n",
    "legs_['low_quality_legs_2'] = 0\n",
    "# Flag the low quality legs\n",
    "\n",
    "for k, signal_categories_ in enumerate(signal_categories):\n",
    "    if k == 0:\n",
    "        threshold_col = 'low_quality_legs_1'\n",
    "    elif k == 1:\n",
    "        threshold_col = 'low_quality_legs_2'\n",
    "    print('NIVEAU DU SEUIL : ', k+1)\n",
    "    print('-------------------------')\n",
    "    for cat in signal_categories_:\n",
    "        #if cat == 'road':\n",
    "        #    continue\n",
    "        #else:\n",
    "        legs_.loc[(legs_['mode'].isin(signal_categories_[cat]['modes'])) & \n",
    "                 ((legs_.max_signlalloss_meters > signal_categories_[cat]['psa']) | \n",
    "                 (legs_.rel_max_signalloss > signal_categories_[cat]['psr'])), threshold_col] = 1\n",
    "\n",
    "        lost_traces = len(legs_.loc[(legs_['mode'].isin(signal_categories_[cat]['modes'])) \n",
    "                          & (legs_[threshold_col] == 1)]) / len(legs_.loc[legs_['mode'].isin(signal_categories_[cat]['modes'])]) * 100\n",
    "        \n",
    "        print('Category : ', cat, \n",
    "              ' | PSA : ', signal_categories_[cat]['psa'], \n",
    "              ' | PSR : ', signal_categories_[cat]['psr'], \n",
    "              ' \\n Part des traces perdues : ', round(lost_traces, 1), '%')\n",
    "    print('-------------------------')\n",
    "\n",
    "# Identify the users who are always bad in terms on signal acquisition\n",
    "legs_avg_signal_loss = legs_[['user_id_motiontag', 'max_signlalloss_meters', 'rel_max_signalloss']].groupby('user_id_motiontag').mean()#.unique()\n",
    "legs_avg_signal_loss.reset_index(inplace=True)\n",
    "list_of_bad_users_1 = legs_avg_signal_loss.loc[(legs_avg_signal_loss.rel_max_signalloss >\n",
    "                                              legs_avg_signal_loss.rel_max_signalloss.quantile(0.99)) |\n",
    "                                             (legs_avg_signal_loss.max_signlalloss_meters > \n",
    "                                              legs_avg_signal_loss.max_signlalloss_meters.quantile(0.99)), 'user_id_motiontag'].unique()\n",
    "list_of_bad_users_2 = legs_avg_signal_loss.loc[(legs_avg_signal_loss.rel_max_signalloss >\n",
    "                                              legs_avg_signal_loss.rel_max_signalloss.quantile(0.99)) |\n",
    "                                             (legs_avg_signal_loss.max_signlalloss_meters > \n",
    "                                              legs_avg_signal_loss.max_signlalloss_meters.quantile(0.99)), 'user_id_motiontag'].unique()\n",
    "legs_.loc[legs_.user_id_motiontag.isin(list_of_bad_users_1), 'low_quality_legs_1'] = 1\n",
    "legs_.loc[legs_.user_id_motiontag.isin(list_of_bad_users_2), 'low_quality_legs_2'] = 1\n",
    "print('List of users with constant low signal quality : ', list_of_bad_users_2, \n",
    "      '\\n eq. to ', round(len(list_of_bad_users_2) / len(legs_) * 100, 2), '%')\n",
    "print('-------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdbc639-b6ec-4812-9ea1-ff630bc91968",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_['usr_w_constant_bad_signal'] = 0\n",
    "legs_.loc[legs_['user_id_motiontag'].isin(list_of_bad_users_1) | legs_['user_id_motiontag'].isin(list_of_bad_users_2), 'usr_w_constant_bad_signal'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a4af9-1f4d-4f70-b2fc-d4e56c68c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(legs.user_id_motiontag.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0b3b1-3a41-41ec-9285-e8684ab52b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_reorder = legs_[['leg_id','user_id_motiontag', 'user_id_fors', 'type', 'started_at',\n",
    "       'started_at_timezone', 'finished_at', 'finished_at_timezone', 'length', 'length_leg',\n",
    "       'detected_mode', 'mode', 'geometry', 'started_on',\n",
    "       'misdetected_completely', 'merged', 'confirmed_at', 'created_at', 'updated_at',\n",
    "       'started_at_in_timezone', 'finished_at_in_timezone',\n",
    "       'confirmed_at_in_timezone', 'created_at_in_timezone',\n",
    "       'updated_at_in_timezone',\n",
    "       'point_per_linestring', 'max_signlalloss_meters', \n",
    "       'rel_max_signalloss', 'low_quality_legs_1', 'low_quality_legs_2',\n",
    "       'usr_w_constant_bad_signal']].astype({'length':'int32','length_leg':'int32'}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc0bd8-0327-4b27-9f44-4cea423e529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE TO PICKLES\n",
    "legs_reorder.to_crs(crs=target_crs).to_pickle(\"../Data/dumps_motiontag/storyline_time_space_filters/legs_filter.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac4234-40ea-4cff-8c4a-6481180bd4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b173a6f0-575a-46e1-8318-d5576879ae17",
   "metadata": {},
   "source": [
    "### Map matching snap traces to network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652331b-f8f6-44d4-a6b3-ec27a053767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#legs_reorder = legs_reorder.to_crs(crs=target_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79865a17-bfdb-4d12-8477-47c9e7a5be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_bad_leg = legs_reorder[(legs_reorder.detected_mode=='Mode::Walk')].sample(300)\n",
    "xyt.plot_gps(sample_bad_leg.rename(columns={'user_id_fors':'user_id'}), geo_columns='geometry')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfed113-2034-4c7f-9b9d-a866802d33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import LineString, Point\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Extract relevant columns for map matching\n",
    "gps_data = sample_bad_leg[['leg_id', 'started_at','finished_at','geometry']].copy().reset_index(drop=True)\n",
    "\n",
    "# Geoapify API details\n",
    "api_key = \"c48fe7a7644f4647a84b3dae1da1a549\"\n",
    "url = f\"https://api.geoapify.com/v1/mapmatching?apiKey={api_key}\"\n",
    "headers = CaseInsensitiveDict()\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "\n",
    "# Function to interpolate timestamps along a LineString\n",
    "def interpolate_timestamps(line, started_at, finished_at):\n",
    "    num_points = len(list(line.coords))\n",
    "    total_seconds = (finished_at - started_at).total_seconds()\n",
    "    times = [started_at + timedelta(seconds=(total_seconds / (num_points - 1)) * i) for i in range(num_points)]\n",
    "    interpolated_points = [line.interpolate(line.length * i / (num_points - 1)) for i in range(num_points)]\n",
    "    return [{'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'), 'location': [point.x, point.y]} for time, point in zip(times, interpolated_points)]\n",
    "\n",
    "# Function to perform map matching for a list of waypoints\n",
    "def map_match(waypoints):\n",
    "    data = {\n",
    "        'mode': 'walk',  # Adjust mode based on your data type (e.g., drive, bike, walk)\n",
    "        'waypoints': waypoints\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "        if resp.status_code == 200:\n",
    "            return resp.json()\n",
    "        else:\n",
    "            print(f\"Error: {resp.status_code}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "        return None\n",
    "\n",
    "# List to store mapped trajectories\n",
    "mapped_trajectories = []\n",
    "\n",
    "# Loop over leg_ids in gps_data\n",
    "for index, row in tqdm(gps_data.iterrows()):\n",
    "    leg_id = row['leg_id']\n",
    "    line = row['geometry']\n",
    "    started_at = row['started_at']\n",
    "    finished_at = row['finished_at']\n",
    "    \n",
    "    # Interpolate timestamps and locations along the LineString\n",
    "    waypoints = interpolate_timestamps(line, started_at, finished_at)\n",
    "    \n",
    "    # Perform map matching for the interpolated waypoints\n",
    "    matched_coords = map_match(waypoints)\n",
    "    \n",
    "    if matched_coords:\n",
    "        #print(f\"Matched coordinates for leg_id {leg_id}\")\n",
    "        mapped_trajectories.append({'leg_id': leg_id, 'matched_coords': matched_coords})\n",
    "        # Process matched_coords as needed (e.g., store in DataFrame)\n",
    "        # Example: gps_data.loc[index, 'matched_coords'] = matched_coords\n",
    "    else:\n",
    "        print(f\"Failed to match coordinates for leg_id {leg_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15948506-244b-4f27-9e97-2784b811e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "# Initialize lists to store data\n",
    "leg_ids = []\n",
    "matched_locations = []\n",
    "original_locations = []\n",
    "\n",
    "# Iterate through mapped_trajectories\n",
    "for traj in mapped_trajectories:\n",
    "    leg_id = traj['leg_id']\n",
    "    matched_coords = traj['matched_coords']['features'][0]['geometry']['coordinates']\n",
    "    \n",
    "    # Extract matched and original locations\n",
    "    matched_location = matched_coords[0]  # First point is the matched location\n",
    "\n",
    "    # Append data to lists\n",
    "    leg_ids.append(leg_id)\n",
    "    matched_locations.append(matched_location)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'leg_id': leg_ids,\n",
    "    'snapped_geom': matched_locations,\n",
    "})\n",
    "\n",
    "# Convert coordinates to Point objects for spatial operations (optional)\n",
    "df['snapped_geom'] = df['snapped_geom'].apply(lambda coords: LineString(coords))\n",
    "\n",
    "# Merge with original traces\n",
    "gps_data_mapped = pd.merge(gps_data, df, on='leg_id', how='left')\n",
    "\n",
    "# Build two dfs\n",
    "gdf_original = gpd.GeoDataFrame(gps_data_mapped[['leg_id', 'started_at', 'finished_at', 'geometry']], geometry='geometry', crs=target_crs)\n",
    "gdf_snapped = gpd.GeoDataFrame(gps_data_mapped[['leg_id', 'started_at', 'finished_at', 'snapped_geom']].dropna(), geometry='snapped_geom', crs=target_crs)\n",
    "\n",
    "# Add length in meter and number of points of each geometry\n",
    "gdf_original['length_original_m'] = gdf_original.to_crs(crs=\"EPSG:2056\").geometry.length\n",
    "gdf_original['points_per_linestring_original'] = gdf_original['geometry'].apply(lambda x: len(list(x.coords)))\n",
    "\n",
    "# Set geometry to the snapped geometries\n",
    "gdf_snapped['length_snapped_m'] = gdf_snapped.to_crs(crs=\"EPSG:2056\").snapped_geom.length\n",
    "gdf_snapped['points_per_linestring_snapped'] = gdf_snapped['snapped_geom'].apply(lambda x: len(list(x.coords)))\n",
    "\n",
    "# Append lenght\n",
    "gps_data_mapped = pd.merge(gps_data_mapped, gdf_original[['leg_id','length_original_m','points_per_linestring_original']],\n",
    "                          on = 'leg_id', how='left')\n",
    "gps_data_mapped = pd.merge(gps_data_mapped, gdf_snapped[['leg_id','length_snapped_m','points_per_linestring_snapped']],\n",
    "                          on = 'leg_id', how='left')\n",
    "\n",
    "# Compute diff in length\n",
    "gps_data_mapped['diff_length_snapping'] = (gdf_snapped['length_snapped_m'] - gdf_original['length_original_m']) / gdf_snapped['length_snapped_m'] \n",
    "\n",
    "# Add the \"matching_failed\" column based on the given conditions\n",
    "\n",
    "#condition2 = gps_data_mapped['length_snapped_m'] < gps_data_mapped['length_original_m']\n",
    "# Définir la tolérance\n",
    "tolérance = 0.5  # Vous pouvez ajuster cette valeur selon vos besoins\n",
    "# Calculer la condition pour les longueurs proches\n",
    "condition1 = gps_data_mapped['points_per_linestring_snapped'] <= gps_data_mapped['points_per_linestring_original']\n",
    "\n",
    "condition2 = np.abs(gps_data_mapped['length_original_m'] - gps_data_mapped['length_snapped_m']) > tolérance * gps_data_mapped['length_original_m']\n",
    "\n",
    "\n",
    "gps_data_mapped['matching_failed'] =  condition2 | condition1\n",
    "\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "gps_data_mapped.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98fe37-a957-417d-96c1-dcc6bfbfdb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_data_mapped.loc[~gps_data_mapped.matching_failed, 'diff_length_snapping'].dropna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61983e4a-51cf-4829-aff3-1214cbe89d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_data_mapped.loc[~gps_data_mapped.matching_failed, 'diff_length_snapping'].dropna().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea50119-3147-473c-a96b-f11a99e6fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "#gps_data_mapped.to_pickle(\"../Data/temp_files/sample_snapping_eval_walk.pkl\")\n",
    "#gdf_original.to_file(\"../Data/temp_files/sample_snapping_eval_original_walk.geojson\", driver='GeoJSON')\n",
    "#gdf_snapped.to_file(\"../Data/temp_files/sample_snapping_eval_snapped_walk.geojson\", driver='GeoJSON')\n",
    "\n",
    "# Reimport data\n",
    "#gps_data_mapped = pd.read_pickle('../Data/temp_files/sample_snapping_eval_car.pkl')\n",
    "#tolérance = 0.3  # Vous pouvez ajuster cette valeur selon vos besoins\n",
    "## Calculer la condition pour les longueurs proches\n",
    "#condition1 = gps_data_mapped['points_per_linestring_snapped'] <= gps_data_mapped['points_per_linestring_original']\n",
    "#condition2 = np.abs(gps_data_mapped['length_original_m'] - gps_data_mapped['length_snapped_m']) > tolérance * gps_data_mapped['length_original_m']\n",
    "#\n",
    "#\n",
    "#gps_data_mapped['matching_failed'] =  condition2 | condition1\n",
    "#gps_data_mapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b5883-073f-4a7b-bf55-e0e167c89720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing\n",
    "# gps_data_mapped.loc[gps_data_mapped.leg_id == '416eed70-b1b3-447e-a43c-5a0deb07eb28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5510a40-8ab5-4bb5-8940-0ce6a2a19ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d149ba55-f926-474c-a0e7-7beec39f056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gps_data_mapped[~gps_data_mapped.matching_failed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52695913-2515-4203-bb25-08108c2d520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sort the DataFrame by original length for better visualization\n",
    "gps_data_mapped_sorted = gps_data_mapped[~gps_data_mapped.matching_failed].dropna().sort_values(by='length_original_m').reset_index(drop=True)\n",
    "gps_data_mapped_sorted = gps_data_mapped_sorted[gps_data_mapped_sorted.length_original_m < 40000]\n",
    "\n",
    "# Create a bar plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Set positions for the bars\n",
    "ind = np.arange(len(gps_data_mapped_sorted))\n",
    "width = 0.5\n",
    "\n",
    "# Plot the original lengths\n",
    "ax.bar(ind - width/2, gps_data_mapped_sorted['length_original_m'], width, label='Original Length (m)')\n",
    "\n",
    "# Plot the snapped lengths\n",
    "ax.bar(ind + width/2, gps_data_mapped_sorted['length_snapped_m'], width, label='Snapped Length (m)')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel(\"Identifiant de l'étape\")\n",
    "ax.set_ylabel(\"Longueur de l'étape (m)\")\n",
    "ax.set_title(\"Comparaison entre la trace brute et la trace cartospondance \\n (mode marche uniquement)\")\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(gps_data_mapped_sorted['leg_id'], rotation=90, size=5)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa65b06-a717-43b1-bc65-c9309f981920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Trier le DataFrame par longueur originale pour une meilleure visualisation\n",
    "gps_data_mapped_sorted = gps_data_mapped[~gps_data_mapped.matching_failed].dropna()\n",
    "gps_data_mapped_sorted = gps_data_mapped_sorted[gps_data_mapped_sorted.length_original_m < 40000]\n",
    "\n",
    "gps_data_mapped_sorted['relative_difference'] = (gps_data_mapped_sorted['length_snapped_m'] - gps_data_mapped_sorted['length_original_m']) / gps_data_mapped_sorted['length_original_m'] * 100\n",
    "\n",
    "gps_data_mapped_filtered = gps_data_mapped_sorted.sort_values(by='relative_difference').reset_index(drop=True)\n",
    "\n",
    "# Créer un graphique à barres pour visualiser les différences relatives par identifiant de l'étape\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 8))\n",
    "\n",
    "# Définir les positions des barres\n",
    "ind = np.arange(len(gps_data_mapped_filtered))\n",
    "width = 0.4\n",
    "\n",
    "# Tracer les différences relatives\n",
    "ax[0].bar(ind, gps_data_mapped_filtered['relative_difference'], width, color='#97C8A6')\n",
    "\n",
    "# Ajouter des labels, un titre et une légende\n",
    "ax[0].set_xlabel(\"Identifiant de l'étape\")\n",
    "ax[0].set_ylabel(\"Différence relative (%)\")\n",
    "#ax[0].set_yticklabels(size=15)\n",
    "ax[0].set_title(\"Différence relative entre la longueur observée \\n et la longueur cartospondance \\n (mode voiture uniquement)\")\n",
    "ax[0].set_xticks(ind)\n",
    "ax[0].set_xticklabels(gps_data_mapped_filtered['leg_id'], rotation=90, size=5)\n",
    "\n",
    "# Créer un histogramme pour visualiser la distribution des différences relatives\n",
    "ax[1].hist(gps_data_mapped_filtered['relative_difference'], bins=50, color='#97C8A6', edgecolor='white')\n",
    "\n",
    "# Ajouter des labels et un titre pour l'histogramme\n",
    "ax[1].set_xlabel(\"Différence relative (%)\")\n",
    "ax[1].set_ylabel(\"Fréquence\")\n",
    "ax[1].set_title(\"Distribution des différences relatives entre la longueur observée \\net la longueur cartospondance \\n (mode voiture uniquement)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be639292-7639-44ac-af3a-892096130343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa815d4-3e8b-40be-8406-859c0f68fe5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4959b8-bf67-40e9-a830-79aff188afc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30614cb-6c1a-48f1-8149-0db57e5aa3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8166c-16fa-41a0-ad65-ee0891b58b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfdece49-8e13-4668-a0d8-15f484a93329",
   "metadata": {},
   "source": [
    "### Control the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08e09f-262e-4a38-b0b8-a20018ebfcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(legs_[legs_.low_quality_legs_1 ==1]) / len(legs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453cf0d7-a149-442f-9711-129a23722693",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(legs_[legs_.low_quality_legs_2 == 1]) / len(legs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87755ee5-956d-4d24-b88e-f79f21e8e92d",
   "metadata": {},
   "source": [
    "### Test the different thresholds (for sensitivity analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce56b2-00be-4aad-8ac8-d8a6465a8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in signal_categories[0]:\n",
    "    print('\\n---')\n",
    "    print(cat)\n",
    "    df_sorted = legs_.loc[legs_['mode'].isin(signal_categories_[cat]['modes'])].sort_values(by=[\"rel_max_signalloss\", \"max_signlalloss_meters\"])\n",
    "    # Calculate the number of rows to keep 98% of the data\n",
    "    num_rows_to_keep = int(0.95 * len(df_sorted))\n",
    "    \n",
    "    # Select the rows that represent the top 98% of the data\n",
    "    df_filtered = df_sorted.iloc[:num_rows_to_keep]\n",
    "    \n",
    "    # Get the threshold values for \"rel_max_signalloss\" and \"max_signlalloss_meters\"\n",
    "    print('Threshold for max_signlalloss_meters', df_filtered[\"max_signlalloss_meters\"].max())\n",
    "    print('Threshold for rel_max_signalloss', df_filtered[\"rel_max_signalloss\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2d7122-3555-4381-aab7-c92d964a113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(legs_.loc[(legs_['mode'].isin(mode_active)) & \n",
    "            ((legs_.max_signlalloss_meters > 750) | \n",
    "            (legs_.rel_max_signalloss > 0.7))]) / len(legs_.loc[legs_['mode'].isin(mode_road)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a55303d-cbac-4e7a-bcaf-c2c2eb482ac4",
   "metadata": {},
   "source": [
    "### Re-import pickles to save it to shapefiles and recombined the split pickles (in canton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86a151-616b-48a1-a5df-63837d0b64e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# List of pickle file names\n",
    "pickle_files = [\n",
    "    'legs_FRA_filtered',\n",
    "    'legs_GG_FRA_filtered',\n",
    "    'legs_VD_part_1_filtered',\n",
    "    'legs_VD_part_2_filtered',\n",
    "    'legs_VD_part_3_filtered',\n",
    "    'legs_GE_filtered'\n",
    "]\n",
    "\n",
    "intput_directory = 'gps_canton'\n",
    "\n",
    "output_directory = 'gps_canton/shp'\n",
    "os.makedirs(output_directory)\n",
    "\n",
    "# Load and concatenate the pickle files\n",
    "dfs = []\n",
    "for file in pickle_files:\n",
    "    df = pd.read_pickle(os.path.join(intput_directory, f'{file}.pkl'))\n",
    "    df.to_crs(crs=target_crs).to_file(os.path.join(output_directory, f'{file}.shp'))\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Dump the combined DataFrame to a pickle file\n",
    "combined_df.to_pickle('gps_canton/legs_filtered.pkl')\n",
    "combined_df.to_crs(crs=target_crs).to_file('gps_canton/shp/legs_filtered.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54bbb5d-d422-495a-b31f-185e10dbf494",
   "metadata": {},
   "source": [
    "### For more testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16472aa6-7606-4c52-b6c2-de11206b54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## USE THIS LINE TO SAVE EXAMPLES OF HIGH SIGNAL LOSS\n",
    "#legs_.loc[legs_.max_signlalloss_meters > legs_.max_distance_meters.quantile(0.75)].to_crs(crs=target_crs).to_file('gg_fra_75_quant.geojson', driver='GeoJSON')\n",
    "\n",
    "#legs_.loc[(legs_['mode'].isin(mode_road)) & (legs_.max_signlalloss_meters < road_psa) & (legs_.rel_max_signalloss < road_psr)].to_crs(crs=target_crs).to_file('gg_fra_mode_road_.geojson', driver='GeoJSON')\n",
    "\n",
    "#legs_.loc[(legs_['mode'].isin(mode_active)) & (legs_.max_signlalloss_meters > active_psa) & (legs_.rel_max_signalloss > active_psr)].to_crs(crs=target_crs).to_file('gg_fra_mode_active.geojson', driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3c0c1-db11-4da0-911b-960da5ef8900",
   "metadata": {},
   "outputs": [],
   "source": [
    "##We can access the coordinates of a Linestring as follows:\n",
    "#legs.geometry[30831] reads the object linestring\n",
    "#type(legs.geometry[30831]) must be a shapely.geometry.linestring.LineString\n",
    "#list(legs_.geometry[30831].coords) displays the coordinate tuples from which we can compute the point-to-point distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba8de0d-809b-42dd-8bdd-a953fe3f2f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
