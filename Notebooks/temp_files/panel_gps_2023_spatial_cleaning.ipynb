{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5003603-5904-41a6-bd71-91cce763d32e",
   "metadata": {},
   "source": [
    "# Readme Panel Lémanique\n",
    "Ce notebook reprend les données brutes GPS 2023 du Panel Lémanique et en fourni une première phase de nettoyage et de filtrage des données. A savoir deux niveau de \"perte de signal\" identifiés par les colonnes 'low_quality_legs_1' (env. 5% de traces éliminées) et 'low_quality_legs_2' (env. 7% de traces éliminées).\n",
    "## GPS tracking\n",
    "Les données GPS sont issues de la phase de collecte sur 21 jours au printemps 2023.\n",
    "## Fichiers de base utilisés\n",
    "- Brut: gps_panel_lemanique_by_motion_tag.csv\n",
    "- Lines: lines.geojson, fichié fourni par Elisa Tirindelli le 17/08/23 --> renommé legs.geojson\n",
    "- Points: points.geojson, fichié fourni par Elisa Tirindelli le 17/08/23 --> renommé staypoints.geojson\n",
    "- Fichiers de raccordement: Localisation_domicile.csv par Florian Masse (trouvé sur le serveur LASUR)\n",
    "- Géoinformation: Verkehrszonen_Schweiz_NPVM_2017.shp, Zone de Trafic du modèle voyageur suisse\n",
    "- Questionnaire: EPFL_vague1_v4.csv, fourni par Alexis Gumy le 21/09/23\n",
    "## Nettoyage par Elisa\n",
    "- élimination des déplacements qui se répètent pour chaque personne plus qu’une fois (pour l'elimiation de bias dans des données)\n",
    "- élimination des déplacements “triangles” (déplacement qui revient au même endroit plusieurs fois), les déplacements qui partent (ou arrivent) deux fois du (au) même endroits\n",
    "- élimination des trajets (dans un même déplacement) qui partent plus tard qu’une demi heure après le trajet avant\n",
    "- corriger les déplacements qui contienne plus qu’un trajet sur la même ligne (regrouper tous les trajets consecutives sur une ligne dans un seul trajet)\n",
    "- corriger le temps de trajet (aussi la distance) du déplacement (les recalculer pour tenir en compte le trajets qui ont été éliminé)\n",
    "- réfléchir sur les déplacements qui comprennent plus que 3/4 trajets TP (assez improbable)\n",
    "## Nettoyage complémentaires par Marc-Edouard (voir dans le notebook ci-dessous)\n",
    "- Enlever les étapes avec perte de signal (i.e. discontinuous legs) -> perte de 530 traces / 669808\n",
    "- Segmentation des données par Canton pour faciliter la manipulation des données\n",
    "- Gérer les legs non géolocalisés (beeline between OD)\n",
    "- Calcul du nombre d'observation moyen par répondant.e\n",
    "\n",
    "## Spotted issues\n",
    "- 'CH14886', 'CH15539' are duplicates in the vague1_v4 file\n",
    "- 'FR13508', 'CH8035', 'CH14765' are not in the vague1_v4 file but appear in the gps file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d69600-5761-467c-a60d-2edc1dff9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "from shapely import geometry, ops\n",
    "from shapely.geometry import MultiLineString, LineString, Point\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe421f-f4dd-4786-9ba8-65cb233c6cf0",
   "metadata": {},
   "source": [
    "## Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469aea0b-992c-432d-90ec-5a0dd63a163b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 s, sys: 11.7 s, total: 31.3 s\n",
      "Wall time: 34.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define the CRS you want to use (e.g., EPSG:4326 for WGS84)\n",
    "target_crs = 'EPSG:4326'\n",
    "\n",
    "# load geo data\n",
    "\n",
    "raw = pd.read_pickle('gps_panel_lemanique_by_motion_tag.pkl').filter(items=['id','type','started_at','finished_at'])\n",
    "\n",
    "legs = pd.read_pickle('legs.pkl').reset_index()\n",
    "legs = gpd.GeoDataFrame(legs, geometry=\"geometry\")\n",
    "\n",
    "points = pd.read_pickle('staypoints.pkl')\n",
    "points = gpd.GeoDataFrame(points, geometry=\"geometry\")\n",
    "\n",
    "## Load geodata as csv if no pickle were created\n",
    "#raw = pd.read_csv('gps_panel_lemanique_by_motion_tag.csv')\n",
    "#legs = gpd.read_file('legs.geojson', crs=target_crs)\n",
    "#points = gpd.read_file('staypoints.geojson', crs=target_crs)\n",
    "\n",
    "## Retrieve the started_at and finished_at from original files as Elisa's were missing\n",
    "##For legs\n",
    "#legs = pd.read_pickle('legs.pkl')\n",
    "#legs = pd.merge(raw[['id','started_at','finished_at']], legs, on='id', how='right')\n",
    "#legs = legs.filter(items=['id', 'started_at', 'finished_at', 'type', 'strtd__',\n",
    "#       'dtctd_m', 'mode', 'IDNO', 'geometry'])\n",
    "#legs.rename(columns={'strtd__':'started_at_timezone', 'dtctd_m':'detected_mode'}, inplace=True)\n",
    "#legs.set_index('id').to_pickle('legs.pkl')\n",
    "## For staypoints\n",
    "#points = pd.read_pickle('staypoints.pkl')\n",
    "#points = pd.merge(raw[['id','started_at','finished_at']], points, on='id', how='right')\n",
    "#points = points.filter(items=['id', 'started_at', 'finished_at', 'type', 'strtd__',\n",
    "#                              'purpose', 'IDNO', 'geometry'])\n",
    "#points.rename(columns={'strtd__':'started_at_timezone'}, inplace=True)\n",
    "#points.set_index('id').to_pickle('staypoints.pkl')\n",
    "\n",
    "\n",
    "#load survey data\n",
    "full_survey = pd.read_csv('../Vague1/EPFL_vague1_v4.csv', low_memory=False)\n",
    "dom =  pd.read_csv('../Vague1/Localisation_domicile.csv', low_memory=False)\n",
    "dom = gpd.GeoDataFrame(dom, geometry=gpd.points_from_xy(dom.dom_long, dom.dom_lat), crs=target_crs)\n",
    "del dom['dom_long']\n",
    "del dom['dom_lat']\n",
    "\n",
    "#load official data\n",
    "TAZ = gpd.read_file('../Vague1/Verkehrszonen_Schweiz_NPVM_2017_shp/Verkehrszonen_Schweiz_NPVM_2017.shp')\n",
    "TAZ = TAZ[['ID_Agglo', 'N_Agglo', 'N_KT', 'ID_Gem', 'geometry']]\n",
    "TAZ = TAZ.to_crs(crs=target_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb354225-d097-421f-90ed-9ee7c6827c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>started_at_timezone</th>\n",
       "      <th>finished_at</th>\n",
       "      <th>finished_at_timezone</th>\n",
       "      <th>length</th>\n",
       "      <th>detected_mode</th>\n",
       "      <th>mode</th>\n",
       "      <th>purpose</th>\n",
       "      <th>geometry</th>\n",
       "      <th>confirmed_at</th>\n",
       "      <th>started_on</th>\n",
       "      <th>misdetected_completely</th>\n",
       "      <th>merged</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>started_at_in_timezone</th>\n",
       "      <th>finished_at_in_timezone</th>\n",
       "      <th>confirmed_at_in_timezone</th>\n",
       "      <th>created_at_in_timezone</th>\n",
       "      <th>updated_at_in_timezone</th>\n",
       "      <th>IDNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75074f7e-43cf-45ba-85a1-870d3ef09a4e</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-04-30 12:12:28</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-05-01 05:10:22</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home</td>\n",
       "      <td>0020000001000010e6401a25305bc9b07a40475dbf1402...</td>\n",
       "      <td>2023-05-21 11:26:59</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-01 15:29:57</td>\n",
       "      <td>2023-05-21 11:26:59</td>\n",
       "      <td>2023-04-30 12:12:28</td>\n",
       "      <td>2023-05-01 05:10:22</td>\n",
       "      <td>2023-05-21 11:26:59</td>\n",
       "      <td>2023-05-01 15:29:57</td>\n",
       "      <td>2023-05-21 11:26:59</td>\n",
       "      <td>CH3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>051d1613-b29a-4598-90d4-2365bf58132b</td>\n",
       "      <td>Track</td>\n",
       "      <td>2023-05-01 05:10:22</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-05-01 05:16:18</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>4999.0</td>\n",
       "      <td>Mode::Car</td>\n",
       "      <td>Mode::Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0020000002000010e600000043401a25305bc9b07a4047...</td>\n",
       "      <td>2023-05-01 19:41:23</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-01 15:29:57</td>\n",
       "      <td>2023-05-02 18:32:09</td>\n",
       "      <td>2023-05-01 05:10:22</td>\n",
       "      <td>2023-05-01 05:16:18</td>\n",
       "      <td>2023-05-01 19:41:23</td>\n",
       "      <td>2023-05-01 15:29:57</td>\n",
       "      <td>2023-05-02 18:32:09</td>\n",
       "      <td>CH3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4311fb87-42d1-4950-b330-f06a18459bc1</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-05-01 05:16:18</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-05-01 15:11:05</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>work</td>\n",
       "      <td>0020000001000010e6401a4772606fac60404759fb7c42...</td>\n",
       "      <td>2023-05-01 19:41:19</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-01 15:29:58</td>\n",
       "      <td>2023-05-01 19:41:19</td>\n",
       "      <td>2023-05-01 05:16:18</td>\n",
       "      <td>2023-05-01 15:11:05</td>\n",
       "      <td>2023-05-01 19:41:19</td>\n",
       "      <td>2023-05-01 15:29:58</td>\n",
       "      <td>2023-05-01 19:41:19</td>\n",
       "      <td>CH3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92957703-71b4-4ae0-a1d2-3a2862d74a43</td>\n",
       "      <td>Track</td>\n",
       "      <td>2023-05-01 15:11:05</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-05-01 15:20:08</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>5668.0</td>\n",
       "      <td>Mode::Car</td>\n",
       "      <td>Mode::Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0020000002000010e600000069401a4772606fac604047...</td>\n",
       "      <td>2023-05-01 19:41:16</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-01 15:29:58</td>\n",
       "      <td>2023-05-01 19:41:16</td>\n",
       "      <td>2023-05-01 15:11:05</td>\n",
       "      <td>2023-05-01 15:20:08</td>\n",
       "      <td>2023-05-01 19:41:16</td>\n",
       "      <td>2023-05-01 15:29:58</td>\n",
       "      <td>2023-05-01 19:41:16</td>\n",
       "      <td>CH3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a274be2e-e5ea-46b2-a32a-32a711dca4e0</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-05-01 15:20:08</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-05-01 17:41:37</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home</td>\n",
       "      <td>0020000001000010e6401a2520382ec59040475dc168eb...</td>\n",
       "      <td>2023-05-01 19:41:09</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-01 19:29:18</td>\n",
       "      <td>2023-05-01 19:41:09</td>\n",
       "      <td>2023-05-01 15:20:08</td>\n",
       "      <td>2023-05-01 17:41:37</td>\n",
       "      <td>2023-05-01 19:41:09</td>\n",
       "      <td>2023-05-01 19:29:18</td>\n",
       "      <td>2023-05-01 19:41:09</td>\n",
       "      <td>CH3181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   type           started_at  \\\n",
       "0  75074f7e-43cf-45ba-85a1-870d3ef09a4e   Stay  2023-04-30 12:12:28   \n",
       "1  051d1613-b29a-4598-90d4-2365bf58132b  Track  2023-05-01 05:10:22   \n",
       "2  4311fb87-42d1-4950-b330-f06a18459bc1   Stay  2023-05-01 05:16:18   \n",
       "3  92957703-71b4-4ae0-a1d2-3a2862d74a43  Track  2023-05-01 15:11:05   \n",
       "4  a274be2e-e5ea-46b2-a32a-32a711dca4e0   Stay  2023-05-01 15:20:08   \n",
       "\n",
       "  started_at_timezone          finished_at finished_at_timezone  length  \\\n",
       "0       Europe/Zurich  2023-05-01 05:10:22        Europe/Zurich     NaN   \n",
       "1       Europe/Zurich  2023-05-01 05:16:18        Europe/Zurich  4999.0   \n",
       "2       Europe/Zurich  2023-05-01 15:11:05        Europe/Zurich     NaN   \n",
       "3       Europe/Zurich  2023-05-01 15:20:08        Europe/Zurich  5668.0   \n",
       "4       Europe/Zurich  2023-05-01 17:41:37        Europe/Zurich     NaN   \n",
       "\n",
       "  detected_mode       mode purpose  \\\n",
       "0           NaN        NaN    home   \n",
       "1     Mode::Car  Mode::Car     NaN   \n",
       "2           NaN        NaN    work   \n",
       "3     Mode::Car  Mode::Car     NaN   \n",
       "4           NaN        NaN    home   \n",
       "\n",
       "                                            geometry         confirmed_at  \\\n",
       "0  0020000001000010e6401a25305bc9b07a40475dbf1402...  2023-05-21 11:26:59   \n",
       "1  0020000002000010e600000043401a25305bc9b07a4047...  2023-05-01 19:41:23   \n",
       "2  0020000001000010e6401a4772606fac60404759fb7c42...  2023-05-01 19:41:19   \n",
       "3  0020000002000010e600000069401a4772606fac604047...  2023-05-01 19:41:16   \n",
       "4  0020000001000010e6401a2520382ec59040475dc168eb...  2023-05-01 19:41:09   \n",
       "\n",
       "   started_on  misdetected_completely  merged           created_at  \\\n",
       "0  2023-04-30                   False   False  2023-05-01 15:29:57   \n",
       "1  2023-05-01                   False   False  2023-05-01 15:29:57   \n",
       "2  2023-05-01                   False   False  2023-05-01 15:29:58   \n",
       "3  2023-05-01                   False   False  2023-05-01 15:29:58   \n",
       "4  2023-05-01                   False   False  2023-05-01 19:29:18   \n",
       "\n",
       "            updated_at started_at_in_timezone finished_at_in_timezone  \\\n",
       "0  2023-05-21 11:26:59    2023-04-30 12:12:28     2023-05-01 05:10:22   \n",
       "1  2023-05-02 18:32:09    2023-05-01 05:10:22     2023-05-01 05:16:18   \n",
       "2  2023-05-01 19:41:19    2023-05-01 05:16:18     2023-05-01 15:11:05   \n",
       "3  2023-05-01 19:41:16    2023-05-01 15:11:05     2023-05-01 15:20:08   \n",
       "4  2023-05-01 19:41:09    2023-05-01 15:20:08     2023-05-01 17:41:37   \n",
       "\n",
       "  confirmed_at_in_timezone created_at_in_timezone updated_at_in_timezone  \\\n",
       "0      2023-05-21 11:26:59    2023-05-01 15:29:57    2023-05-21 11:26:59   \n",
       "1      2023-05-01 19:41:23    2023-05-01 15:29:57    2023-05-02 18:32:09   \n",
       "2      2023-05-01 19:41:19    2023-05-01 15:29:58    2023-05-01 19:41:19   \n",
       "3      2023-05-01 19:41:16    2023-05-01 15:29:58    2023-05-01 19:41:16   \n",
       "4      2023-05-01 19:41:09    2023-05-01 19:29:18    2023-05-01 19:41:09   \n",
       "\n",
       "     IDNO  \n",
       "0  CH3181  \n",
       "1  CH3181  \n",
       "2  CH3181  \n",
       "3  CH3181  \n",
       "4  CH3181  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_pickle('gps_panel_lemanique_by_motion_tag.pkl')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e467d8ea-ad84-4adf-9c7e-d9eff048f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(raw.IDNO.unique()).to_csv('list_IDNO_tracking_gps.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "012f2bd9-3795-4521-b531-406036af6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.sample(n=100).to_csv('sample_panel_lemanic_kanaha.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5d3078-7038-4573-a15d-1032f3c98028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>started_at_timezone</th>\n",
       "      <th>finished_at</th>\n",
       "      <th>finished_at_timezone</th>\n",
       "      <th>length</th>\n",
       "      <th>detected_mode</th>\n",
       "      <th>mode</th>\n",
       "      <th>purpose</th>\n",
       "      <th>geometry</th>\n",
       "      <th>confirmed_at</th>\n",
       "      <th>started_on</th>\n",
       "      <th>misdetected_completely</th>\n",
       "      <th>merged</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>started_at_in_timezone</th>\n",
       "      <th>finished_at_in_timezone</th>\n",
       "      <th>confirmed_at_in_timezone</th>\n",
       "      <th>created_at_in_timezone</th>\n",
       "      <th>updated_at_in_timezone</th>\n",
       "      <th>IDNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75074f7e-43cf-45ba-85a1-870d3ef09a4e</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-04-30 12:12:28</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-05-01 05:10:22</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home</td>\n",
       "      <td>0020000001000010e6401a25305bc9b07a40475dbf1402...</td>\n",
       "      <td>2023-05-21 11:26:59</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-01 15:29:57</td>\n",
       "      <td>2023-05-21 11:26:59</td>\n",
       "      <td>2023-04-30 12:12:28</td>\n",
       "      <td>2023-05-01 05:10:22</td>\n",
       "      <td>2023-05-21 11:26:59</td>\n",
       "      <td>2023-05-01 15:29:57</td>\n",
       "      <td>2023-05-21 11:26:59</td>\n",
       "      <td>CH3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4311fb87-42d1-4950-b330-f06a18459bc1</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-05-01 05:16:18</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-05-01 15:11:05</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>work</td>\n",
       "      <td>0020000001000010e6401a4772606fac60404759fb7c42...</td>\n",
       "      <td>2023-05-01 19:41:19</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-01 15:29:58</td>\n",
       "      <td>2023-05-01 19:41:19</td>\n",
       "      <td>2023-05-01 05:16:18</td>\n",
       "      <td>2023-05-01 15:11:05</td>\n",
       "      <td>2023-05-01 19:41:19</td>\n",
       "      <td>2023-05-01 15:29:58</td>\n",
       "      <td>2023-05-01 19:41:19</td>\n",
       "      <td>CH3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a274be2e-e5ea-46b2-a32a-32a711dca4e0</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-05-01 15:20:08</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-05-01 17:41:37</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home</td>\n",
       "      <td>0020000001000010e6401a2520382ec59040475dc168eb...</td>\n",
       "      <td>2023-05-01 19:41:09</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-01 19:29:18</td>\n",
       "      <td>2023-05-01 19:41:09</td>\n",
       "      <td>2023-05-01 15:20:08</td>\n",
       "      <td>2023-05-01 17:41:37</td>\n",
       "      <td>2023-05-01 19:41:09</td>\n",
       "      <td>2023-05-01 19:29:18</td>\n",
       "      <td>2023-05-01 19:41:09</td>\n",
       "      <td>CH3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11c2c50a-98b8-4608-924e-31644efaed2d</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-05-01 17:53:05</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-05-01 19:11:15</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>family_friends</td>\n",
       "      <td>0020000001000010e6401a71caf485787a4047654899cc...</td>\n",
       "      <td>2023-05-02 04:17:36</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-01 22:49:53</td>\n",
       "      <td>2023-05-02 04:17:39</td>\n",
       "      <td>2023-05-01 17:53:05</td>\n",
       "      <td>2023-05-01 19:11:15</td>\n",
       "      <td>2023-05-02 04:17:36</td>\n",
       "      <td>2023-05-01 22:49:53</td>\n",
       "      <td>2023-05-02 04:17:39</td>\n",
       "      <td>CH3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3111307b-2939-4ae3-b6dc-e54ba07ebfa6</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-05-01 19:24:23</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-05-02 05:13:13</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home</td>\n",
       "      <td>0020000001000010e6401a2536a0a5fd5440475dbe54ab...</td>\n",
       "      <td>2023-05-02 18:28:43</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-02 10:23:29</td>\n",
       "      <td>2023-05-02 18:28:43</td>\n",
       "      <td>2023-05-01 19:24:23</td>\n",
       "      <td>2023-05-02 05:13:13</td>\n",
       "      <td>2023-05-02 18:28:43</td>\n",
       "      <td>2023-05-02 10:23:29</td>\n",
       "      <td>2023-05-02 18:28:43</td>\n",
       "      <td>CH3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231360</th>\n",
       "      <td>7b5c65d4-7e86-43d5-a789-2b7236eb0ed3</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-04-26 10:45:53</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-04-26 11:07:18</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>leisure</td>\n",
       "      <td>0020000001000010e640201721fa25cb6c4047b2779cef...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-04-26 13:59:07</td>\n",
       "      <td>2023-04-26 13:59:07</td>\n",
       "      <td>2023-04-26 10:45:53</td>\n",
       "      <td>2023-04-26 11:07:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-26 13:59:07</td>\n",
       "      <td>2023-04-26 13:59:07</td>\n",
       "      <td>CH23198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231362</th>\n",
       "      <td>4e8f34fb-02d5-43be-b506-9855a3511b47</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-04-26 11:18:01</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-04-26 11:22:16</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wait</td>\n",
       "      <td>0020000001000010e640201a1aa74b33044047b220c3c4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-04-26 13:59:07</td>\n",
       "      <td>2023-04-26 13:59:07</td>\n",
       "      <td>2023-04-26 11:18:01</td>\n",
       "      <td>2023-04-26 11:22:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-26 13:59:07</td>\n",
       "      <td>2023-04-26 13:59:07</td>\n",
       "      <td>CH23198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231364</th>\n",
       "      <td>88de2000-4484-4303-a3b0-b9cf06af24f1</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-04-26 11:37:41</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-04-26 13:59:01</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0020000001000010e640200ab637ca71a94047aba7496a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-04-26 16:00:14</td>\n",
       "      <td>2023-04-26 16:00:14</td>\n",
       "      <td>2023-04-26 11:37:41</td>\n",
       "      <td>2023-04-26 13:59:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-26 16:00:14</td>\n",
       "      <td>2023-04-26 16:00:14</td>\n",
       "      <td>CH23198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231366</th>\n",
       "      <td>0d365bfb-457a-4498-bf2c-d83b3588285a</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-04-26 15:40:22</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-04-26 15:47:27</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>errand</td>\n",
       "      <td>0020000001000010e6401b6632fd3bb8cc40474098695f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-04-27 07:54:17</td>\n",
       "      <td>2023-04-27 07:54:17</td>\n",
       "      <td>2023-04-26 15:40:22</td>\n",
       "      <td>2023-04-26 15:47:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-27 07:54:17</td>\n",
       "      <td>2023-04-27 07:54:17</td>\n",
       "      <td>CH23198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231367</th>\n",
       "      <td>3af83e43-effd-4136-b439-60b6f56f0bd7</td>\n",
       "      <td>Stay</td>\n",
       "      <td>2023-04-26 15:58:42</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>2023-04-27 06:57:23</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home</td>\n",
       "      <td>0020000001000010e6401b61b03d1f1a4d40473db6972b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-04-27 07:54:17</td>\n",
       "      <td>2023-04-27 07:54:17</td>\n",
       "      <td>2023-04-26 15:58:42</td>\n",
       "      <td>2023-04-27 06:57:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-27 07:54:17</td>\n",
       "      <td>2023-04-27 07:54:17</td>\n",
       "      <td>CH23198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561562 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id  type           started_at  \\\n",
       "0        75074f7e-43cf-45ba-85a1-870d3ef09a4e  Stay  2023-04-30 12:12:28   \n",
       "2        4311fb87-42d1-4950-b330-f06a18459bc1  Stay  2023-05-01 05:16:18   \n",
       "4        a274be2e-e5ea-46b2-a32a-32a711dca4e0  Stay  2023-05-01 15:20:08   \n",
       "6        11c2c50a-98b8-4608-924e-31644efaed2d  Stay  2023-05-01 17:53:05   \n",
       "8        3111307b-2939-4ae3-b6dc-e54ba07ebfa6  Stay  2023-05-01 19:24:23   \n",
       "...                                       ...   ...                  ...   \n",
       "1231360  7b5c65d4-7e86-43d5-a789-2b7236eb0ed3  Stay  2023-04-26 10:45:53   \n",
       "1231362  4e8f34fb-02d5-43be-b506-9855a3511b47  Stay  2023-04-26 11:18:01   \n",
       "1231364  88de2000-4484-4303-a3b0-b9cf06af24f1  Stay  2023-04-26 11:37:41   \n",
       "1231366  0d365bfb-457a-4498-bf2c-d83b3588285a  Stay  2023-04-26 15:40:22   \n",
       "1231367  3af83e43-effd-4136-b439-60b6f56f0bd7  Stay  2023-04-26 15:58:42   \n",
       "\n",
       "        started_at_timezone          finished_at finished_at_timezone  length  \\\n",
       "0             Europe/Zurich  2023-05-01 05:10:22        Europe/Zurich     NaN   \n",
       "2             Europe/Zurich  2023-05-01 15:11:05        Europe/Zurich     NaN   \n",
       "4             Europe/Zurich  2023-05-01 17:41:37        Europe/Zurich     NaN   \n",
       "6             Europe/Zurich  2023-05-01 19:11:15        Europe/Zurich     NaN   \n",
       "8             Europe/Zurich  2023-05-02 05:13:13        Europe/Zurich     NaN   \n",
       "...                     ...                  ...                  ...     ...   \n",
       "1231360       Europe/Zurich  2023-04-26 11:07:18        Europe/Zurich     NaN   \n",
       "1231362       Europe/Zurich  2023-04-26 11:22:16        Europe/Zurich     NaN   \n",
       "1231364       Europe/Zurich  2023-04-26 13:59:01        Europe/Zurich     NaN   \n",
       "1231366       Europe/Zurich  2023-04-26 15:47:27        Europe/Zurich     NaN   \n",
       "1231367       Europe/Zurich  2023-04-27 06:57:23        Europe/Zurich     NaN   \n",
       "\n",
       "        detected_mode mode         purpose  \\\n",
       "0                 NaN  NaN            home   \n",
       "2                 NaN  NaN            work   \n",
       "4                 NaN  NaN            home   \n",
       "6                 NaN  NaN  family_friends   \n",
       "8                 NaN  NaN            home   \n",
       "...               ...  ...             ...   \n",
       "1231360           NaN  NaN         leisure   \n",
       "1231362           NaN  NaN            wait   \n",
       "1231364           NaN  NaN         unknown   \n",
       "1231366           NaN  NaN          errand   \n",
       "1231367           NaN  NaN            home   \n",
       "\n",
       "                                                  geometry  \\\n",
       "0        0020000001000010e6401a25305bc9b07a40475dbf1402...   \n",
       "2        0020000001000010e6401a4772606fac60404759fb7c42...   \n",
       "4        0020000001000010e6401a2520382ec59040475dc168eb...   \n",
       "6        0020000001000010e6401a71caf485787a4047654899cc...   \n",
       "8        0020000001000010e6401a2536a0a5fd5440475dbe54ab...   \n",
       "...                                                    ...   \n",
       "1231360  0020000001000010e640201721fa25cb6c4047b2779cef...   \n",
       "1231362  0020000001000010e640201a1aa74b33044047b220c3c4...   \n",
       "1231364  0020000001000010e640200ab637ca71a94047aba7496a...   \n",
       "1231366  0020000001000010e6401b6632fd3bb8cc40474098695f...   \n",
       "1231367  0020000001000010e6401b61b03d1f1a4d40473db6972b...   \n",
       "\n",
       "                confirmed_at  started_on  misdetected_completely  merged  \\\n",
       "0        2023-05-21 11:26:59  2023-04-30                   False   False   \n",
       "2        2023-05-01 19:41:19  2023-05-01                   False   False   \n",
       "4        2023-05-01 19:41:09  2023-05-01                   False   False   \n",
       "6        2023-05-02 04:17:36  2023-05-01                   False   False   \n",
       "8        2023-05-02 18:28:43  2023-05-01                   False   False   \n",
       "...                      ...         ...                     ...     ...   \n",
       "1231360                  NaN  2023-04-26                   False   False   \n",
       "1231362                  NaN  2023-04-26                   False   False   \n",
       "1231364                  NaN  2023-04-26                   False   False   \n",
       "1231366                  NaN  2023-04-26                   False   False   \n",
       "1231367                  NaN  2023-04-26                   False   False   \n",
       "\n",
       "                  created_at           updated_at started_at_in_timezone  \\\n",
       "0        2023-05-01 15:29:57  2023-05-21 11:26:59    2023-04-30 12:12:28   \n",
       "2        2023-05-01 15:29:58  2023-05-01 19:41:19    2023-05-01 05:16:18   \n",
       "4        2023-05-01 19:29:18  2023-05-01 19:41:09    2023-05-01 15:20:08   \n",
       "6        2023-05-01 22:49:53  2023-05-02 04:17:39    2023-05-01 17:53:05   \n",
       "8        2023-05-02 10:23:29  2023-05-02 18:28:43    2023-05-01 19:24:23   \n",
       "...                      ...                  ...                    ...   \n",
       "1231360  2023-04-26 13:59:07  2023-04-26 13:59:07    2023-04-26 10:45:53   \n",
       "1231362  2023-04-26 13:59:07  2023-04-26 13:59:07    2023-04-26 11:18:01   \n",
       "1231364  2023-04-26 16:00:14  2023-04-26 16:00:14    2023-04-26 11:37:41   \n",
       "1231366  2023-04-27 07:54:17  2023-04-27 07:54:17    2023-04-26 15:40:22   \n",
       "1231367  2023-04-27 07:54:17  2023-04-27 07:54:17    2023-04-26 15:58:42   \n",
       "\n",
       "        finished_at_in_timezone confirmed_at_in_timezone  \\\n",
       "0           2023-05-01 05:10:22      2023-05-21 11:26:59   \n",
       "2           2023-05-01 15:11:05      2023-05-01 19:41:19   \n",
       "4           2023-05-01 17:41:37      2023-05-01 19:41:09   \n",
       "6           2023-05-01 19:11:15      2023-05-02 04:17:36   \n",
       "8           2023-05-02 05:13:13      2023-05-02 18:28:43   \n",
       "...                         ...                      ...   \n",
       "1231360     2023-04-26 11:07:18                      NaN   \n",
       "1231362     2023-04-26 11:22:16                      NaN   \n",
       "1231364     2023-04-26 13:59:01                      NaN   \n",
       "1231366     2023-04-26 15:47:27                      NaN   \n",
       "1231367     2023-04-27 06:57:23                      NaN   \n",
       "\n",
       "        created_at_in_timezone updated_at_in_timezone     IDNO  \n",
       "0          2023-05-01 15:29:57    2023-05-21 11:26:59   CH3181  \n",
       "2          2023-05-01 15:29:58    2023-05-01 19:41:19   CH3181  \n",
       "4          2023-05-01 19:29:18    2023-05-01 19:41:09   CH3181  \n",
       "6          2023-05-01 22:49:53    2023-05-02 04:17:39   CH3181  \n",
       "8          2023-05-02 10:23:29    2023-05-02 18:28:43   CH3181  \n",
       "...                        ...                    ...      ...  \n",
       "1231360    2023-04-26 13:59:07    2023-04-26 13:59:07  CH23198  \n",
       "1231362    2023-04-26 13:59:07    2023-04-26 13:59:07  CH23198  \n",
       "1231364    2023-04-26 16:00:14    2023-04-26 16:00:14  CH23198  \n",
       "1231366    2023-04-27 07:54:17    2023-04-27 07:54:17  CH23198  \n",
       "1231367    2023-04-27 07:54:17    2023-04-27 07:54:17  CH23198  \n",
       "\n",
       "[561562 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw[raw['type']=='Stay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cadf94f3-7c23-4363-8ec1-615859079c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4_1_1_R : Combien avez-vous de voiture conventionnelle en état de fonctionnement dans votre ménage ?\n",
    "#Q4_1_2_R : Combien avez-vous de voiture électrique/hybride en état de fonctionnement dans votre ménage ?\n",
    "#Q5 : Quel est le type de motorisation de la voiture que vous utilisez le plus souvent ?\n",
    "#Q6 : Quel est le type de motorisation de la deuxième voiture que vous utilisez le plus souvent ?\n",
    "#Q7 : Pouvez-vous disposer d’une voiture du ménage quand vous le souhaitez ?\n",
    "#Q8 : Vous arrive-t-il de vous faire prêter une voiture par des proches (ami·e·s, famille, etc.) pour vos propres déplacements ou ceux de votre ménage ?\n",
    "#Q9 : Vous arrive-t-il d'utiliser un service d'autopartage (car-sharing, tel que Mobility ou Citiz) ?\n",
    "\n",
    "survey = full_survey[['IDNO','canton_dep','AGGLO_CH_dom','Pays','Groupe', 'Weight', 'ID_COM', 'permis_auto', 'revenu', 'revenuFR','revenuCH','age','formation','Genre_actuel','KLASSE_ARE_dom', 'KLASSE_ARE_trav', 'pays_trav', 'Q4_1_1_R','Q4_1_2_R', 'Q5_R', 'Q6_R', 'Q7', 'Q8', 'Q9']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb04d87-9cdf-4608-95cb-7dfe874d9731",
   "metadata": {},
   "source": [
    "##  Merge geodata with survey data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101fc53b-cd14-4fa7-8119-5f0423d02634",
   "metadata": {},
   "source": [
    "TRANSFORM MULTILINESTRINGS INTO LINESTRINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a23cab4c-f335-4423-858a-12f8bf758e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LineString         667106\n",
       "MultiLineString      2702\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legs.geometry.geom_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749db9cd-ad41-4180-8fe4-4e212209dc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LineString    669278\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rewrite continuous MultiLineString into LineString geometries\n",
    "legs['geometry'] = legs['geometry'].apply(lambda geom: ops.linemerge(geom) if isinstance(geom, MultiLineString) else geom)\n",
    "# Remove the discontinuous Multilinestrings (only the discontinuous lines remain after the previous operation)\n",
    "# note: an alternative would be to explode the discontinuous multiline, but then we don't have the departure / arrival time: legs.explode(index_parts=True)\n",
    "legs = legs.loc[legs.geometry.geom_type != 'MultiLineString',:]\n",
    "# Point counts for each LineString\n",
    "legs['point_per_linestring'] = legs['geometry'].apply(lambda geom: len(geom.coords))\n",
    "#legs['dep_coordinates'] = legs['geometry'].apply(lambda geom: geom.coords[0])\n",
    "legs.geometry.geom_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb52d5cf-ff29-4d61-bf76-6683f6d27fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#legs = legs.merge(survey, on='IDNO', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc79044e-1f08-4f3e-9ad8-66ff1a63ead2",
   "metadata": {},
   "source": [
    "## Split the population per Canton\n",
    "After the code below we eventually obtain the following segmentation:\n",
    "- VD        58%\n",
    "- GE        19.6%\n",
    "- FRA       16.4%\n",
    "- GG_FRA    5.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "339de2d0-5cb7-4a64-85b6-c75ab4fc1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial join between the domicile geolocation and the TAZ information\n",
    "canton_dom = gpd.sjoin(dom, TAZ, how='left')\n",
    "del canton_dom['ID_Gem']\n",
    "del canton_dom['index_right']\n",
    "# Since the TAZ info is only for CH, we parse manually French resident\n",
    "survey = survey.merge(canton_dom, on='IDNO', how='left')\n",
    "survey.loc[survey.Pays == '2', 'N_KT'] = 'FRANCE'\n",
    "# Rename columns to be more explicit\n",
    "survey.rename(columns={'ID_Agglo':'dom_ID_Agglo','N_Agglo':'dom_N_Agglo','N_KT':'dom_N_KT'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23bea2c5-c919-4810-aff1-3a0db9ee5653",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRONG ONE WAY TO INFER WOULD BE TO TAKE THE FIRST DEPARTURE OF DAY ONLY, BUT RESULTS ARE NOT CONVINCING...\n",
    "\n",
    "## We still have missing Kanton of residence, mostly because the respondant did not answer the address question (Q14)\n",
    "## Below we infer the address from the gps data i.e. the most recurent canton in the trip departures\n",
    "#\n",
    "## We use the column dep_coordinates and do a spatial join on TAZ info\n",
    "#departure = gpd.GeoDataFrame(legs[['IDNO','dep_coordinates']], geometry=gpd.points_from_xy(legs.dep_coordinates.str[0], legs.dep_coordinates.str[1]), crs=target_crs)\n",
    "#del departure['dep_coordinates']\n",
    "#departure = gpd.sjoin(departure, TAZ[['N_KT','geometry']], how='left')\n",
    "#del departure['index_right']\n",
    "## Then we find the most recurent Kanton in all departures for each user\n",
    "#kt_dep = departure[['IDNO', 'N_KT']].groupby(by=['IDNO']).agg(pd.Series.mode).reset_index()\n",
    "#kt_dep.rename(columns={'N_KT':'dom_KT'},inplace=True)\n",
    "## Join it to the survey dataframe\n",
    "#survey = pd.merge(survey, kt_dep, on='IDNO')\n",
    "## We can now complement the missing survey info with the one above\n",
    "#survey.loc[survey.dom_N_KT.isna(), 'dom_N_KT'] = survey.loc[survey.dom_N_KT.isna(), 'KT_dep']\n",
    "#survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0605fb0-863c-402f-993f-8083f243a6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>started_at</th>\n",
       "      <th>finished_at</th>\n",
       "      <th>type</th>\n",
       "      <th>started_at_timezone</th>\n",
       "      <th>detected_mode</th>\n",
       "      <th>mode</th>\n",
       "      <th>IDNO</th>\n",
       "      <th>geometry</th>\n",
       "      <th>point_per_linestring</th>\n",
       "      <th>canton_dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>051d1613-b29a-4598-90d4-2365bf58132b</td>\n",
       "      <td>2023-05-01 05:10:22</td>\n",
       "      <td>2023-05-01 05:16:18</td>\n",
       "      <td>Track</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>Mode::Car</td>\n",
       "      <td>Mode::Car</td>\n",
       "      <td>CH3181</td>\n",
       "      <td>LINESTRING (6.53632 46.73239, 6.53632 46.73239...</td>\n",
       "      <td>67</td>\n",
       "      <td>VD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92957703-71b4-4ae0-a1d2-3a2862d74a43</td>\n",
       "      <td>2023-05-01 15:11:05</td>\n",
       "      <td>2023-05-01 15:20:08</td>\n",
       "      <td>Track</td>\n",
       "      <td>Europe/Zurich</td>\n",
       "      <td>Mode::Car</td>\n",
       "      <td>Mode::Car</td>\n",
       "      <td>CH3181</td>\n",
       "      <td>LINESTRING (6.56977 46.70299, 6.56977 46.70299...</td>\n",
       "      <td>105</td>\n",
       "      <td>VD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id           started_at  \\\n",
       "0  051d1613-b29a-4598-90d4-2365bf58132b  2023-05-01 05:10:22   \n",
       "1  92957703-71b4-4ae0-a1d2-3a2862d74a43  2023-05-01 15:11:05   \n",
       "\n",
       "           finished_at   type started_at_timezone detected_mode       mode  \\\n",
       "0  2023-05-01 05:16:18  Track       Europe/Zurich     Mode::Car  Mode::Car   \n",
       "1  2023-05-01 15:20:08  Track       Europe/Zurich     Mode::Car  Mode::Car   \n",
       "\n",
       "     IDNO                                           geometry  \\\n",
       "0  CH3181  LINESTRING (6.53632 46.73239, 6.53632 46.73239...   \n",
       "1  CH3181  LINESTRING (6.56977 46.70299, 6.56977 46.70299...   \n",
       "\n",
       "   point_per_linestring canton_dep  \n",
       "0                    67         VD  \n",
       "1                   105         VD  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge to staypoint and leg dataframe\n",
    "# We eventually use the column \"canton_dep\" provided by Alexis Gumy as he created the weights based on this one.\n",
    "legs = pd.merge(legs, survey[['IDNO','canton_dep']], on='IDNO', how='left')\n",
    "# Replace categories with name of canton\n",
    "legs.replace({'canton_dep':{'1':'GE', '2':'VD', '5':'GG_FRA','6':'FRA'}}, inplace=True)\n",
    "# Drop IDNO CH14886 and CH15539 that are duplicates in the servey with conflicting info\n",
    "legs = legs.loc[(~legs.IDNO.isin(['CH15539', 'CH14886']))]\n",
    "# Drop IDNO 'FR13508', 'CH8035', 'CH14765' that are not in the survey but in gps\n",
    "legs = legs.loc[~legs.IDNO.isin(['FR13508', 'CH8035', 'CH14765'])]\n",
    "legs.reset_index(drop=True, inplace=True)\n",
    "## Delete the coordinate columns that create geometry conflicts later on\n",
    "#del legs['dep_coordinates']\n",
    "legs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0142a6c6-1c52-43c8-9ca4-5e3a05eaa293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "canton_dep\n",
       "VD        0.584818\n",
       "GE        0.196025\n",
       "FRA       0.164199\n",
       "GG_FRA    0.054958\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legs.canton_dep.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b7b549-de88-4c4d-a647-be70be07bb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory 'gps_canton' already exists. Aborting.\n"
     ]
    }
   ],
   "source": [
    "# Specify the column based on which you want to split the DataFrame\n",
    "split_column = 'canton_dep'\n",
    "\n",
    "output_directory = 'gps_canton'\n",
    "\n",
    "# Get unique values from the split column\n",
    "unique_values = legs[split_column].unique()\n",
    "\n",
    "# Check if the output directory already exists\n",
    "if os.path.exists(output_directory):\n",
    "    print(f\"Output directory '{output_directory}' already exists. Aborting.\")\n",
    "else:\n",
    "    # Create the output directory\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "    # Split the DataFrame into smaller DataFrames based on unique values\n",
    "    split_dataframes = {value: legs[legs[split_column] == value] for value in unique_values}\n",
    "\n",
    "    # Save each smaller DataFrame as a pickle file\n",
    "    for value, df in split_dataframes.items():\n",
    "        pickle_filename = os.path.join(output_directory, f'legs_{value}.pkl')\n",
    "        df.to_pickle(pickle_filename)\n",
    "        print(f\"Saved '{pickle_filename}'\")\n",
    "\n",
    "    # Save each smaller DataFrame as a pickle file and GeoJSON file, and reset the index\n",
    "    for value, df in split_dataframes.items():\n",
    "        # Reset the index\n",
    "        #df = df.reset_index(drop=True)\n",
    "        \n",
    "        # Save as pickle file\n",
    "        pickle_filename = os.path.join(output_directory, f'legs_{value}.pkl')\n",
    "        df.to_pickle(pickle_filename)\n",
    "        print(f\"Saved '{pickle_filename}'\")\n",
    "\n",
    "        # Save as GeoJSON file\n",
    "        #geojson_filename = os.path.join(output_directory, f'legs_{value}.geojson')\n",
    "        #df.to_file(geojson_filename, driver='GeoJSON')\n",
    "        #print(f\"Saved '{geojson_filename}'\")\n",
    "\n",
    "    #Split legs_VD in three even df\n",
    "    legs_vd = pd.read_pickle('gps_canton/legs_VD.pkl')\n",
    "    parts_legs_vd = np.array_split(legs_vd, 3)\n",
    "    output_directory = 'gps_canton'\n",
    "    for i, part in enumerate(parts_legs_vd):\n",
    "        part.to_pickle(os.path.join(output_directory, f'legs_VD_part_{i+1}.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b435b-34af-454e-967a-9eaed2a16456",
   "metadata": {},
   "source": [
    "## Nettoyage des pertes de signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac136e85-f1c4-47ee-9f21-ced672c44645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: road\n",
      "Modes: ['Mode::Car', 'Mode::Motorbike', 'Mode::Bus', 'Mode::Tram', 'Mode::Subway', 'Mode::KickScooter', 'Mode::LightRail', 'Mode::Other', 'Mode::TaxiUber', 'Mode::Carsharing', 'Mode::Ecar']\n",
      "PSA: 5000\n",
      "PSR: 0.6\n"
     ]
    }
   ],
   "source": [
    "## DEFINE THE MODE SPLIT TO APPLY DIFFERENT THRESHOLDS TO EACH MODE\n",
    "\n",
    "# We propose two level of threshold to be more or less selective in the thresholds (e.g., road_psr_1 and road_psr_2, etc)\n",
    "\n",
    "mode_road = ['Mode::Car', 'Mode::Motorbike', 'Mode::Bus', 'Mode::Tram', 'Mode::Subway', 'Mode::KickScooter', 'Mode::LightRail', 'Mode::Other','Mode::TaxiUber', 'Mode::Carsharing', 'Mode::Ecar']\n",
    "road_psa_1 = 8000\n",
    "road_psr_1 = 0.8\n",
    "road_psa_2 = 5000\n",
    "road_psr_2 = 0.6\n",
    "\n",
    "mode_rail = ['Mode::Train','Mode::RegionalTrain']\n",
    "rail_psa_1 = 100000\n",
    "rail_psr_1 = 0.65\n",
    "rail_psa_2 = 85000\n",
    "rail_psr_2 = 0.50\n",
    "\n",
    "mode_active = ['Mode::Bicycle', 'Mode::Ebicycle', 'Mode::Walk']\n",
    "active_psa_1 = 800\n",
    "active_psr_1 = 0.8\n",
    "active_psa_2 = 750\n",
    "active_psr_2 = 0.7\n",
    "\n",
    "mode_plane_boat = ['Mode::Boat', 'Mode::Airplane']\n",
    "plane_boat_psa_1 = 0\n",
    "plane_boat_psr_1 = 0\n",
    "plane_boat_psa_2 = 0\n",
    "plane_boat_psr_2 = 0\n",
    "\n",
    "# Create dictionaries for each category\n",
    "road_category_1 = {'modes': mode_road, 'psa': road_psa_1, 'psr': road_psr_1}\n",
    "rail_category_1 = {'modes': mode_rail, 'psa': rail_psa_1, 'psr': rail_psr_1}\n",
    "active_category_1 = {'modes': mode_active, 'psa': active_psa_1, 'psr': active_psr_1}\n",
    "plane_boat_category_1 = {'modes': mode_plane_boat, 'psa': plane_boat_psa_1, 'psr': plane_boat_psr_1}\n",
    "\n",
    "road_category_2 = {'modes': mode_road, 'psa': road_psa_2, 'psr': road_psr_2}\n",
    "rail_category_2 = {'modes': mode_rail, 'psa': rail_psa_2, 'psr': rail_psr_2}\n",
    "active_category_2 = {'modes': mode_active, 'psa': active_psa_2, 'psr': active_psr_2}\n",
    "plane_boat_category_2 = {'modes': mode_plane_boat, 'psa': plane_boat_psa_2, 'psr': plane_boat_psr_2}\n",
    "\n",
    "# Create a dictionary to store the categories\n",
    "signal_categories = [{\n",
    "    'road': road_category_1,\n",
    "    'rail': rail_category_1,\n",
    "    'mode_active': active_category_1,\n",
    "    'mode_plane_boat': plane_boat_category_1},{\n",
    "    'road': road_category_2,\n",
    "    'rail': rail_category_2,\n",
    "    'mode_active': active_category_2,\n",
    "    'mode_plane_boat': plane_boat_category_2}]\n",
    "\n",
    "# Example: Accessing values for the 'road' category\n",
    "print(\"Category: road\")\n",
    "print(\"Modes:\", signal_categories[1]['road']['modes'])\n",
    "print(\"PSA:\", signal_categories[1]['road']['psa'])\n",
    "print(\"PSR:\", signal_categories[1]['road']['psr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82786a8d-553d-45cf-815b-b51332d04115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the maximum distance in meters between two points in a LineString\n",
    "def calculate_max_distance(line):\n",
    "    # Extract the coordinates of the LineString into a list of points\n",
    "    points = list(line.coords)\n",
    "    \n",
    "    # Initialize a list to store the distances between consecutive points\n",
    "    distances = []\n",
    "\n",
    "    # Iterate through the points to calculate and store the distances\n",
    "    for i in range(len(points) - 1):\n",
    "        point1 = Point(points[i])\n",
    "        point2 = Point(points[i + 1])\n",
    "        distance = point1.distance(point2)\n",
    "        distances.append(distance)\n",
    "\n",
    "    # Find the maximum distance from the list of distances\n",
    "    max_distance = max(distances)\n",
    "    \n",
    "    return max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c04c5e0f-e75b-429f-8e59-7507d8695987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECHANTILLON :  GG_FRA\n",
      "-------------------------\n",
      "NIVEAU DU SEUIL :  1\n",
      "-------------------------\n",
      "Category :  road  | PSA :  8000  | PSR :  0.8  \n",
      " Part des traces perdues :  4.2 %\n",
      "Category :  rail  | PSA :  100000  | PSR :  0.65  \n",
      " Part des traces perdues :  5.4 %\n",
      "Category :  mode_active  | PSA :  800  | PSR :  0.8  \n",
      " Part des traces perdues :  4.7 %\n",
      "Category :  mode_plane_boat  | PSA :  0  | PSR :  0  \n",
      " Part des traces perdues :  100.0 %\n",
      "-------------------------\n",
      "NIVEAU DU SEUIL :  2\n",
      "-------------------------\n",
      "Category :  road  | PSA :  5000  | PSR :  0.6  \n",
      " Part des traces perdues :  7.4 %\n",
      "Category :  rail  | PSA :  85000  | PSR :  0.5  \n",
      " Part des traces perdues :  7.6 %\n",
      "Category :  mode_active  | PSA :  750  | PSR :  0.7  \n",
      " Part des traces perdues :  6.8 %\n",
      "Category :  mode_plane_boat  | PSA :  0  | PSR :  0  \n",
      " Part des traces perdues :  100.0 %\n",
      "-------------------------\n",
      "List of users with constant low signal quality :  ['FR2129' 'FR503' 'FR6906' 'FR8311'] \n",
      " eq. to  0.01 %\n",
      "-------------------------\n",
      "ECHANTILLON :  VD_part_1\n",
      "-------------------------\n",
      "NIVEAU DU SEUIL :  1\n",
      "-------------------------\n",
      "Category :  road  | PSA :  8000  | PSR :  0.8  \n",
      " Part des traces perdues :  3.6 %\n",
      "Category :  rail  | PSA :  100000  | PSR :  0.65  \n",
      " Part des traces perdues :  5.2 %\n",
      "Category :  mode_active  | PSA :  800  | PSR :  0.8  \n",
      " Part des traces perdues :  3.7 %\n",
      "Category :  mode_plane_boat  | PSA :  0  | PSR :  0  \n",
      " Part des traces perdues :  100.0 %\n",
      "-------------------------\n",
      "NIVEAU DU SEUIL :  2\n",
      "-------------------------\n",
      "Category :  road  | PSA :  5000  | PSR :  0.6  \n",
      " Part des traces perdues :  6.4 %\n",
      "Category :  rail  | PSA :  85000  | PSR :  0.5  \n",
      " Part des traces perdues :  9.2 %\n",
      "Category :  mode_active  | PSA :  750  | PSR :  0.7  \n",
      " Part des traces perdues :  5.8 %\n",
      "Category :  mode_plane_boat  | PSA :  0  | PSR :  0  \n",
      " Part des traces perdues :  100.0 %\n",
      "-------------------------\n",
      "List of users with constant low signal quality :  ['CH10703' 'CH13240' 'CH17733' 'CH18062' 'CH19239' 'CH25886' 'CH28291'\n",
      " 'CH29289' 'CH3831' 'CH6748' 'CH7869' 'CH9399'] \n",
      " eq. to  0.01 %\n",
      "-------------------------\n",
      "ECHANTILLON :  VD_part_2\n",
      "-------------------------\n",
      "NIVEAU DU SEUIL :  1\n",
      "-------------------------\n",
      "Category :  road  | PSA :  8000  | PSR :  0.8  \n",
      " Part des traces perdues :  3.3 %\n",
      "Category :  rail  | PSA :  100000  | PSR :  0.65  \n",
      " Part des traces perdues :  4.2 %\n",
      "Category :  mode_active  | PSA :  800  | PSR :  0.8  \n",
      " Part des traces perdues :  3.5 %\n",
      "Category :  mode_plane_boat  | PSA :  0  | PSR :  0  \n",
      " Part des traces perdues :  100.0 %\n",
      "-------------------------\n",
      "NIVEAU DU SEUIL :  2\n",
      "-------------------------\n",
      "Category :  road  | PSA :  5000  | PSR :  0.6  \n",
      " Part des traces perdues :  6.0 %\n",
      "Category :  rail  | PSA :  85000  | PSR :  0.5  \n",
      " Part des traces perdues :  7.7 %\n",
      "Category :  mode_active  | PSA :  750  | PSR :  0.7  \n",
      " Part des traces perdues :  5.6 %\n",
      "Category :  mode_plane_boat  | PSA :  0  | PSR :  0  \n",
      " Part des traces perdues :  100.0 %\n",
      "-------------------------\n",
      "List of users with constant low signal quality :  ['CH12070' 'CH13888' 'CH16031' 'CH21735' 'CH22116' 'CH27289' 'CH27868'\n",
      " 'CH28678' 'CH4974' 'CH7551' 'CH7865' 'CH8254'] \n",
      " eq. to  0.01 %\n",
      "-------------------------\n",
      "ECHANTILLON :  VD_part_3\n",
      "-------------------------\n",
      "NIVEAU DU SEUIL :  1\n",
      "-------------------------\n",
      "Category :  road  | PSA :  8000  | PSR :  0.8  \n",
      " Part des traces perdues :  3.8 %\n",
      "Category :  rail  | PSA :  100000  | PSR :  0.65  \n",
      " Part des traces perdues :  4.1 %\n",
      "Category :  mode_active  | PSA :  800  | PSR :  0.8  \n",
      " Part des traces perdues :  3.5 %\n",
      "Category :  mode_plane_boat  | PSA :  0  | PSR :  0  \n",
      " Part des traces perdues :  100.0 %\n",
      "-------------------------\n",
      "NIVEAU DU SEUIL :  2\n",
      "-------------------------\n",
      "Category :  road  | PSA :  5000  | PSR :  0.6  \n",
      " Part des traces perdues :  6.9 %\n",
      "Category :  rail  | PSA :  85000  | PSR :  0.5  \n",
      " Part des traces perdues :  6.8 %\n",
      "Category :  mode_active  | PSA :  750  | PSR :  0.7  \n",
      " Part des traces perdues :  5.5 %\n",
      "Category :  mode_plane_boat  | PSA :  0  | PSR :  0  \n",
      " Part des traces perdues :  100.0 %\n",
      "-------------------------\n",
      "List of users with constant low signal quality :  ['CH12600' 'CH1679' 'CH17638' 'CH19818' 'CH22307' 'CH24706' 'CH25019'\n",
      " 'CH25972' 'CH3014' 'CH4811' 'CH6507' 'CH9884'] \n",
      " eq. to  0.01 %\n",
      "-------------------------\n",
      "ECHANTILLON :  GE\n",
      "-------------------------\n",
      "NIVEAU DU SEUIL :  1\n",
      "-------------------------\n",
      "Category :  road  | PSA :  8000  | PSR :  0.8  \n",
      " Part des traces perdues :  2.3 %\n",
      "Category :  rail  | PSA :  100000  | PSR :  0.65  \n",
      " Part des traces perdues :  4.8 %\n",
      "Category :  mode_active  | PSA :  800  | PSR :  0.8  \n",
      " Part des traces perdues :  3.0 %\n",
      "Category :  mode_plane_boat  | PSA :  0  | PSR :  0  \n",
      " Part des traces perdues :  100.0 %\n",
      "-------------------------\n",
      "NIVEAU DU SEUIL :  2\n",
      "-------------------------\n",
      "Category :  road  | PSA :  5000  | PSR :  0.6  \n",
      " Part des traces perdues :  4.3 %\n",
      "Category :  rail  | PSA :  85000  | PSR :  0.5  \n",
      " Part des traces perdues :  7.6 %\n",
      "Category :  mode_active  | PSA :  750  | PSR :  0.7  \n",
      " Part des traces perdues :  4.9 %\n",
      "Category :  mode_plane_boat  | PSA :  0  | PSR :  0  \n",
      " Part des traces perdues :  100.0 %\n",
      "-------------------------\n",
      "List of users with constant low signal quality :  ['CH1270' 'CH15295' 'CH16053' 'CH17737' 'CH20354' 'CH22801' 'CH23401'\n",
      " 'CH26326' 'CH3044' 'CH9127' 'CH9170'] \n",
      " eq. to  0.01 %\n",
      "-------------------------\n",
      "ECHANTILLON :  FRA\n",
      "-------------------------\n",
      "NIVEAU DU SEUIL :  1\n",
      "-------------------------\n",
      "Category :  road  | PSA :  8000  | PSR :  0.8  \n",
      " Part des traces perdues :  3.3 %\n",
      "Category :  rail  | PSA :  100000  | PSR :  0.65  \n",
      " Part des traces perdues :  8.6 %\n",
      "Category :  mode_active  | PSA :  800  | PSR :  0.8  \n",
      " Part des traces perdues :  5.0 %\n",
      "Category :  mode_plane_boat  | PSA :  0  | PSR :  0  \n",
      " Part des traces perdues :  100.0 %\n",
      "-------------------------\n",
      "NIVEAU DU SEUIL :  2\n",
      "-------------------------\n",
      "Category :  road  | PSA :  5000  | PSR :  0.6  \n",
      " Part des traces perdues :  6.5 %\n",
      "Category :  rail  | PSA :  85000  | PSR :  0.5  \n",
      " Part des traces perdues :  10.8 %\n",
      "Category :  mode_active  | PSA :  750  | PSR :  0.7  \n",
      " Part des traces perdues :  7.2 %\n",
      "Category :  mode_plane_boat  | PSA :  0  | PSR :  0  \n",
      " Part des traces perdues :  100.0 %\n",
      "-------------------------\n",
      "List of users with constant low signal quality :  ['FR10945' 'FR11709' 'FR12113' 'FR13292' 'FR16165' 'FR18224' 'FR18229'\n",
      " 'FR2239' 'FR2427' 'FR5500' 'FR8007' 'FR8956'] \n",
      " eq. to  0.01 %\n",
      "-------------------------\n",
      "CPU times: user 51min 13s, sys: 25.4 s, total: 51min 38s\n",
      "Wall time: 52min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load pickle files\n",
    "KT = ['GG_FRA', 'VD_part_1', 'VD_part_2', 'VD_part_3', 'GE', 'FRA'] #,'GG_FRA', 'VD_part_1', 'VD_part_2', 'VD_part_3', 'GE', 'FRA'\n",
    "intput_directory = 'gps_canton'\n",
    "\n",
    "for KT_ in KT:\n",
    "    legs_ = pd.read_pickle(os.path.join(intput_directory, f'legs_{KT_}.pkl'))\n",
    "    legs_.to_crs(crs=\"EPSG:2056\", inplace=True)\n",
    "    # Apply the calculate_max_distance function to the GeoSeries and store the result in a new column\n",
    "    legs_['max_signlalloss_meters'] = legs_.apply(lambda row: calculate_max_distance(row['geometry']), axis=1)\n",
    "    \n",
    "    # Compute the lenght of each leg\n",
    "    legs_['length_leg'] = legs_['geometry'].apply(lambda geom: geom.length)\n",
    "    \n",
    "    # Compute the relative signal loss\n",
    "    legs_['rel_max_signalloss'] = legs_['max_signlalloss_meters'].div(legs_['length_leg'])\n",
    "    \n",
    "    \n",
    "    # Add a column to flag the legs that we want to filter out\n",
    "    legs_['low_quality_legs_1'] = 0\n",
    "    legs_['low_quality_legs_2'] = 0\n",
    "\n",
    "    # Flag the low quality legs\n",
    "    print('ECHANTILLON : ', KT_)\n",
    "    print('-------------------------')\n",
    "\n",
    "    for k, signal_categories_ in enumerate(signal_categories):\n",
    "        if k == 0:\n",
    "            threshold_col = 'low_quality_legs_1'\n",
    "        elif k == 1:\n",
    "            threshold_col = 'low_quality_legs_2'\n",
    "        print('NIVEAU DU SEUIL : ', k+1)\n",
    "        print('-------------------------')\n",
    "        for cat in signal_categories_:\n",
    "            #if cat == 'road':\n",
    "            #    continue\n",
    "            #else:\n",
    "            legs_.loc[(legs_['mode'].isin(signal_categories_[cat]['modes'])) & \n",
    "                     ((legs_.max_signlalloss_meters > signal_categories_[cat]['psa']) | \n",
    "                     (legs_.rel_max_signalloss > signal_categories_[cat]['psr'])), threshold_col] = 1\n",
    "    \n",
    "            lost_traces = len(legs_.loc[(legs_['mode'].isin(signal_categories_[cat]['modes'])) \n",
    "                              & (legs_[threshold_col] == 1)]) / len(legs_.loc[legs_['mode'].isin(signal_categories_[cat]['modes'])]) * 100\n",
    "            \n",
    "            print('Category : ', cat, \n",
    "                  ' | PSA : ', signal_categories_[cat]['psa'], \n",
    "                  ' | PSR : ', signal_categories_[cat]['psr'], \n",
    "                  ' \\n Part des traces perdues : ', round(lost_traces, 1), '%')\n",
    "        print('-------------------------')\n",
    "    \n",
    "    # Identify the users who are always bad in terms on signal acquisition\n",
    "    legs_avg_signal_loss = legs_[['IDNO', 'max_signlalloss_meters', 'rel_max_signalloss']].groupby('IDNO').mean()#.unique()\n",
    "    legs_avg_signal_loss.reset_index(inplace=True)\n",
    "    list_of_bad_users_1 = legs_avg_signal_loss.loc[(legs_avg_signal_loss.rel_max_signalloss >\n",
    "                                                  legs_avg_signal_loss.rel_max_signalloss.quantile(0.99)) |\n",
    "                                                 (legs_avg_signal_loss.max_signlalloss_meters > \n",
    "                                                  legs_avg_signal_loss.max_signlalloss_meters.quantile(0.99)), 'IDNO'].unique()\n",
    "    list_of_bad_users_2 = legs_avg_signal_loss.loc[(legs_avg_signal_loss.rel_max_signalloss >\n",
    "                                                  legs_avg_signal_loss.rel_max_signalloss.quantile(0.99)) |\n",
    "                                                 (legs_avg_signal_loss.max_signlalloss_meters > \n",
    "                                                  legs_avg_signal_loss.max_signlalloss_meters.quantile(0.99)), 'IDNO'].unique()\n",
    "    legs_.loc[legs_.IDNO.isin(list_of_bad_users_1), 'low_quality_legs_1'] = 1\n",
    "    legs_.loc[legs_.IDNO.isin(list_of_bad_users_2), 'low_quality_legs_2'] = 1\n",
    "    print('List of users with constant low signal quality : ', list_of_bad_users_2, \n",
    "          '\\n eq. to ', round(len(list_of_bad_users_2) / len(legs_) * 100, 2), '%')\n",
    "    print('-------------------------')\n",
    "\n",
    "    #SAVE TO PICKLES\n",
    "    cols_to_save = ['id','started_at', 'finished_at', 'type', 'started_at_timezone','detected_mode', 'mode', \n",
    "                    'IDNO', 'geometry','canton_dep','low_quality_legs_1', 'low_quality_legs_2']\n",
    "    legs_[cols_to_save].to_crs(crs='EPSG:4326').to_pickle(os.path.join(intput_directory, f'legs_{KT_}_filtered.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdece49-8e13-4668-a0d8-15f484a93329",
   "metadata": {},
   "source": [
    "### Control the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b08e09f-262e-4a38-b0b8-a20018ebfcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05813624971519708"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(legs_[legs_.low_quality_legs_1 ==1]) / len(legs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "453cf0d7-a149-442f-9711-129a23722693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08455684666210982"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(legs_[legs_.low_quality_legs_2 == 1]) / len(legs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87755ee5-956d-4d24-b88e-f79f21e8e92d",
   "metadata": {},
   "source": [
    "### Test the different thresholds (for sensitivity analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbce56b2-00be-4aad-8ac8-d8a6465a8302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "road\n",
      "Threshold for max_signlalloss_meters 308916.2503783547\n",
      "Threshold for rel_max_signalloss 0.5062897101520215\n",
      "\n",
      "---\n",
      "rail\n",
      "Threshold for max_signlalloss_meters 255756.0155114675\n",
      "Threshold for rel_max_signalloss 0.7364980586836456\n",
      "\n",
      "---\n",
      "mode_active\n",
      "Threshold for max_signlalloss_meters 63194.8939271471\n",
      "Threshold for rel_max_signalloss 0.7096603823953925\n",
      "\n",
      "---\n",
      "mode_plane_boat\n",
      "Threshold for max_signlalloss_meters 10660778.423309473\n",
      "Threshold for rel_max_signalloss 0.9999959660046349\n"
     ]
    }
   ],
   "source": [
    "for cat in signal_categories[0]:\n",
    "    print('\\n---')\n",
    "    print(cat)\n",
    "    df_sorted = legs_.loc[legs_['mode'].isin(signal_categories_[cat]['modes'])].sort_values(by=[\"rel_max_signalloss\", \"max_signlalloss_meters\"])\n",
    "    # Calculate the number of rows to keep 98% of the data\n",
    "    num_rows_to_keep = int(0.95 * len(df_sorted))\n",
    "    \n",
    "    # Select the rows that represent the top 98% of the data\n",
    "    df_filtered = df_sorted.iloc[:num_rows_to_keep]\n",
    "    \n",
    "    # Get the threshold values for \"rel_max_signalloss\" and \"max_signlalloss_meters\"\n",
    "    print('Threshold for max_signlalloss_meters', df_filtered[\"max_signlalloss_meters\"].max())\n",
    "    print('Threshold for rel_max_signalloss', df_filtered[\"rel_max_signalloss\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a2d7122-3555-4381-aab7-c92d964a113e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.080697628845777"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(legs_.loc[(legs_['mode'].isin(mode_active)) & \n",
    "            ((legs_.max_signlalloss_meters > 750) | \n",
    "            (legs_.rel_max_signalloss > 0.7))]) / len(legs_.loc[legs_['mode'].isin(mode_road)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a55303d-cbac-4e7a-bcaf-c2c2eb482ac4",
   "metadata": {},
   "source": [
    "### Re-import pickles to save it to shapefiles and recombined the split pickles (in canton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f86a151-616b-48a1-a5df-63837d0b64e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:20: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "<timed exec>:20: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "<timed exec>:20: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "<timed exec>:20: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "<timed exec>:20: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "<timed exec>:20: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "<timed exec>:28: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 42s, sys: 30.3 s, total: 5min 12s\n",
      "Wall time: 5min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# List of pickle file names\n",
    "pickle_files = [\n",
    "    'legs_FRA_filtered',\n",
    "    'legs_GG_FRA_filtered',\n",
    "    'legs_VD_part_1_filtered',\n",
    "    'legs_VD_part_2_filtered',\n",
    "    'legs_VD_part_3_filtered',\n",
    "    'legs_GE_filtered'\n",
    "]\n",
    "\n",
    "intput_directory = 'gps_canton'\n",
    "\n",
    "output_directory = 'gps_canton/shp'\n",
    "os.makedirs(output_directory)\n",
    "\n",
    "# Load and concatenate the pickle files\n",
    "dfs = []\n",
    "for file in pickle_files:\n",
    "    df = pd.read_pickle(os.path.join(intput_directory, f'{file}.pkl'))\n",
    "    df.to_crs(crs=target_crs).to_file(os.path.join(output_directory, f'{file}.shp'))\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Dump the combined DataFrame to a pickle file\n",
    "combined_df.to_pickle('gps_canton/legs_filtered.pkl')\n",
    "combined_df.to_crs(crs=target_crs).to_file('gps_canton/shp/legs_filtered.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54bbb5d-d422-495a-b31f-185e10dbf494",
   "metadata": {},
   "source": [
    "### For more testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16472aa6-7606-4c52-b6c2-de11206b54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## USE THIS LINE TO SAVE EXAMPLES OF HIGH SIGNAL LOSS\n",
    "#legs_.loc[legs_.max_signlalloss_meters > legs_.max_distance_meters.quantile(0.75)].to_crs(crs=target_crs).to_file('gg_fra_75_quant.geojson', driver='GeoJSON')\n",
    "\n",
    "#legs_.loc[(legs_['mode'].isin(mode_road)) & (legs_.max_signlalloss_meters < road_psa) & (legs_.rel_max_signalloss < road_psr)].to_crs(crs=target_crs).to_file('gg_fra_mode_road_.geojson', driver='GeoJSON')\n",
    "\n",
    "#legs_.loc[(legs_['mode'].isin(mode_active)) & (legs_.max_signlalloss_meters > active_psa) & (legs_.rel_max_signalloss > active_psr)].to_crs(crs=target_crs).to_file('gg_fra_mode_active.geojson', driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3c0c1-db11-4da0-911b-960da5ef8900",
   "metadata": {},
   "outputs": [],
   "source": [
    "##We can access the coordinates of a Linestring as follows:\n",
    "#legs.geometry[30831] reads the object linestring\n",
    "#type(legs.geometry[30831]) must be a shapely.geometry.linestring.LineString\n",
    "#list(legs_.geometry[30831].coords) displays the coordinate tuples from which we can compute the point-to-point distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba8de0d-809b-42dd-8bdd-a953fe3f2f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
