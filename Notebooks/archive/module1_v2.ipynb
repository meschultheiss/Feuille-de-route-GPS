{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166865c6-1177-4944-8846-280c5be42568",
   "metadata": {},
   "source": [
    "#  Module 1 : Parts modales\n",
    "\n",
    "**Description** : Le but de ce module est de mener un premier calcul des parts modales kilométriques i.e. les distances journalières moyennisées par mode et par motif.\n",
    "\n",
    "**Durée estimée première partie** : 7 jours\n",
    "\n",
    "**Objectifs spécifiques** :\n",
    "- [ ] Sous-échantillonnage des résidents et visiteurs par canton (basé sur le GPS)\n",
    "- [ ] Rééchantillonnage des jours d’observation pour avoir un calendrier continue par usager\n",
    "- [ ] Intégrer le détail des transit\n",
    "- [ ] Distinguer de façon aussi systématique que possible les jours sans déplacement des jours\n",
    "non-détectés et comparaison statistique au jours non-déplacé dans d’autres bases de\n",
    "données\n",
    "- [ ] Recodage des modes et motifs selon besoin des cantons\n",
    "- [ ] Calcul liminaire des parts modales kilométriques et par déplacements\n",
    "- [ ] Ajout des données d’équipement (e.g. type de motorisation principale du ménage)\n",
    "- [ ] Documenter les hypothèses et limites du calcul liminaire des parts modales (e.g. aspects\n",
    "saisonniers, échantillonnage, perte de signal, moyennisation des données longitudinales, ...)\n",
    "\n",
    "**Résultats attendus** : Parts modales kilométriques par mode pour les résidents et visiteurs de chaque canton en vue du calcul des émissions carbone. Il doit être possible de calculer les parts modales en tenant compte des jours non-mobiles.\n",
    "\n",
    "**Sous-échantillonnage** :\n",
    "- Vaud : résident·es du canton\n",
    "- Genève : résident·es du canton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a82e2-45e5-4731-a524-7414b185cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db978265-9330-4054-9728-32b4d8ee4df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab3d72-e25d-4c20-9055-d0942219f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "from shapely import geometry, ops\n",
    "from shapely.geometry import MultiLineString, LineString, Point\n",
    "import os\n",
    "import concurrent.futures\n",
    "from shapely.ops import unary_union\n",
    "import xyt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf133b5-1d51-4369-ad6f-fd9681770f25",
   "metadata": {},
   "source": [
    "### Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5e056-eb6b-42fa-8e51-fe58296bc893",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Définir le CRS du projet (EPSG:4326 for WGS84)\n",
    "target_crs = 'EPSG:4326'\n",
    "print(\"CRS du projet: WGS84 \\n\")\n",
    "\n",
    "#Charger les étapes\n",
    "# Ask the user for input\n",
    "choice = input(\"Do you want to load a sample or the full leg data frame? \\n Enter 'sample' or 'full': \")\n",
    "\n",
    "# Define the file paths\n",
    "if choice.lower() == 'sample':\n",
    "    file_path = '../Data/time_space_filters/legs_filtered_randsample.pkl'\n",
    "elif choice.lower() == 'full':\n",
    "    file_path = '../Data/time_space_filters/legs_filtered.pkl'\n",
    "else:\n",
    "    print(\"Invalid choice. Please enter 'sample' or 'full'.\")\n",
    "\n",
    "# Load the selected data frame\n",
    "try:\n",
    "    legs = pd.read_pickle(file_path)\n",
    "    print(\"Fichier étape chargé\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "legs = gpd.GeoDataFrame(legs, geometry=\"geometry\")\n",
    "\n",
    "del legs['canton_dep']\n",
    "\n",
    "#Charger les activités\n",
    "staypoints = pd.read_pickle('../Data/time_space_filters/staypoints_filtered.pkl').reset_index(drop=True)\n",
    "staypoints = gpd.GeoDataFrame(staypoints, geometry=\"geometry\")\n",
    "print(\"Fichier activité chargé\")\n",
    "\n",
    "#Charger les user_statistics\n",
    "usr_stats = pd.read_csv('../Data/gps_user_statistics.csv')\n",
    "print(\"Fichier statistiques utilisateur·ices chargé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea299a4-42cb-4d44-9fee-31cce0bbbffd",
   "metadata": {},
   "source": [
    "###  Formater les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb11e7-630e-44fd-b629-3199ed3a95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "staypoints['started_at'] = pd.to_datetime(staypoints['started_at'])\n",
    "staypoints['finished_at'] = pd.to_datetime(staypoints['finished_at'])\n",
    "\n",
    "legs['started_at'] = pd.to_datetime(legs['started_at'])\n",
    "legs['finished_at'] = pd.to_datetime(legs['finished_at'])\n",
    "\n",
    "staypoints.rename(columns={'IDNO':'user_id', 'id':'activity_id'}, inplace = True)\n",
    "legs.rename(columns={'IDNO':'user_id', 'id':'leg_id'}, inplace = True)\n",
    "\n",
    "staypoints['lon'] = staypoints.geometry.x\n",
    "staypoints['lat'] = staypoints.geometry.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d252b4-cf3b-4ebd-8b98-d23bfd54bef5",
   "metadata": {},
   "source": [
    "### Ajouter le *next activity_id* aux étapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6a864-2c19-4043-84ba-ccce74c2e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort 'points' and 'legs' by 'started_at' to ensure data is in chronological order\n",
    "staypoints.sort_values(by=['user_id','started_at'], inplace=True, ignore_index=True)\n",
    "legs.sort_values(by=['user_id','started_at'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c019c0-863c-4702-a277-20fa49eb05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs = pd.merge(legs, staypoints[['activity_id', 'previous_leg_id']],\n",
    "               left_on='leg_id', right_on='previous_leg_id', how='left')\n",
    "legs.rename(columns={'activity_id':'leading_stay_id'}, inplace=True)\n",
    "del legs['previous_leg_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6942c1-cb26-40be-b61e-57c102ea73e7",
   "metadata": {},
   "source": [
    "###  Ajouter la durée et la longueur des étapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384b81b-c21a-4f7a-a1b8-86ed7ae2b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Add length in meters\n",
    "legs['length'] = legs.to_crs('EPSG:2056').length\n",
    "# Add the duration in seconds\n",
    "legs['duration'] = (legs['finished_at'] - legs['started_at']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20b595-0d40-446c-acd1-24efe889f816",
   "metadata": {},
   "source": [
    "### Extraire les aires géographiques et les sous-échantillons (Genève et Vaud)\n",
    "Nous utilisons les zones de traffic du Modèle Voyageur de l'ARE.\n",
    "\n",
    "We want to sample :\n",
    "- all the residents of Canton de Genève\n",
    "- all the activities that happen in Canton de Genève"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe12cb3-b769-4dfd-a280-da276f9d8228",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Prompt the user for N_KT value\n",
    "n_kt = 'GE'\n",
    "\n",
    "# Unir les zones de trafic\n",
    "shp_KT = unary_union(TAZ[TAZ.N_KT == n_kt].geometry)\n",
    "\n",
    "# Lister les résident·es du KT\n",
    "list_residents_N_KT = dom.loc[dom.within(shp_KT), 'IDNO'].tolist()\n",
    "\n",
    "# Sous Echantillon des legs des résident·es du KT\n",
    "legs_N_KT = legs.loc[legs.user_id.isin(list_residents_N_KT)].copy()\n",
    "\n",
    "# Liste des activités des résident·es du KT\n",
    "list_staypoints_residents_N_KT = legs_N_KT.dropna().leading_stay_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b0de9-017d-46ff-b9d9-160e133d5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Identifier les activités qui se passent dans le KT\n",
    "staypoints_N_KT = staypoints[staypoints.activity_id.isin(list_staypoints_residents_N_KT)]\n",
    "list_activity_id_in_KT = staypoints_N_KT.loc[staypoints_N_KT.within(shp_KT), 'activity_id'].tolist()\n",
    "\n",
    "#Flagger les activités qui se passent dans le KT\n",
    "legs_N_KT['leading_stay_id_in_KT'] = 0\n",
    "legs_N_KT.loc[legs_N_KT.leading_stay_id.isin(list_activity_id_in_KT), 'leading_stay_id_in_KT'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d3788-640d-46d9-8b56-d788f74d43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajouter le user_id_day\n",
    "legs_N_KT.insert(\n",
    "    1,\"user_id_day\",legs_N_KT[\"user_id\"]\n",
    "    + \"_\" \n",
    "    + legs_N_KT.started_at.dt.year.astype(str)\n",
    "    + legs_N_KT.started_at.dt.month.astype(str).str.zfill(2)\n",
    "    + legs_N_KT.started_at.dt.day.astype(str).str.zfill(2),\n",
    ")\n",
    "legs_N_KT.insert(1, 'leg_date',legs_N_KT.started_at.dt.date)\n",
    "legs_N_KT['leg_date'] = pd.to_datetime(legs_N_KT['leg_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065b6d6e-3ec3-4bef-b451-5e0e7058f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "xyt.plot_gps(staypoints[staypoints.activity_id.isin(list_activity_id_in_KT)].dropna()[:2000], geo_columns='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30a666-7552-4729-8534-1bcd75e8ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "usr = legs_N_KT.user_id.sample(20).tolist()\n",
    "df_ = legs_N_KT.loc[legs_N_KT.user_id.isin(usr)]\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a52505-65ee-437c-9613-8168fb32ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.leg_date.max() - df_.leg_date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51ed55-450d-4c9b-979a-c6b24437dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_daily_modal_distances(df):\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['length'] = df['length'].astype(float)\n",
    "    # Group by 'user_id_day', 'previous_mode', and 'previous_leg_id', then sum the distances\n",
    "    grouped = df.groupby(['user_id', 'user_id_day', 'mode'])['length'].sum().reset_index()\n",
    "\n",
    "    # Pivot the table to have modes as columns\n",
    "    pivoted = grouped.pivot_table(\n",
    "        index=['user_id', 'user_id_day'],\n",
    "        columns='mode',\n",
    "        values='length',\n",
    "        aggfunc='sum'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Resample to include missing days and fill NaNs with different values in different columns\n",
    "    pivoted['date'] = pd.to_datetime(pivoted['user_id_day'].str[-8:])\n",
    "    # Create a date range covering the entire date range for each ID\n",
    "    date_ranges = pivoted.groupby('user_id')['date'].agg(['min', 'max']).reset_index()\n",
    "    date_ranges['leg_date'] = date_ranges.apply(lambda row: pd.date_range(row['min'], row['max'], freq='D'), axis=1)\n",
    "\n",
    "    # Create a Cartesian product of IDs and date ranges\n",
    "    cartesian = date_ranges.explode('leg_date').reset_index(drop=True)\n",
    "\n",
    "    # Complete the original df with a continuous timeline\n",
    "    pivoted_filled = pd.merge(pivoted, cartesian[['user_id', 'leg_date']], how='outer', left_on=['user_id', 'date'],\n",
    "                              right_on=['user_id', 'leg_date'])\n",
    "\n",
    "    # Create 'resample' column and mark as True for added rows, False otherwise\n",
    "    pivoted_filled['resample'] = pivoted_filled['date'].isnull()\n",
    "    del pivoted_filled['date']\n",
    "\n",
    "    # Fill missing values in the user_id_day column\n",
    "    pivoted_filled['user_id_day'] = pivoted_filled.apply(\n",
    "        lambda row: row['user_id_day'] if not pd.isnull(row['user_id_day'])\n",
    "        else row['user_id'] + \"_\" +\n",
    "             row['leg_date'].strftime('%Y%m%d'),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Fill missing values in the modes columns\n",
    "    # Get the columns that start with 'Mode::'\n",
    "    modes_columns = [col for col in pivoted_filled.columns if col.startswith('Mode::')]\n",
    "\n",
    "    # Fill missing values in the 'modes_columns' with 0\n",
    "    pivoted_filled[modes_columns] = pivoted_filled[modes_columns].fillna(0)\n",
    "\n",
    "    # Sort the resulting DataFrame\n",
    "    pivoted_filled.sort_values(by=['user_id', 'leg_date'], inplace=True)\n",
    "\n",
    "    return pivoted_filled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6830783-8568-4043-89cf-c3352a436f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmd = get_daily_modal_distances(df_)#.tail(20)\n",
    "dmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dfeaa4-42f5-4b8d-9ae4-885fd20c84c6",
   "metadata": {},
   "source": [
    "###  Get the mean distance per user in meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa3733-7190-4cda-850e-9258f4dc9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named df\n",
    "# Filter columns that start with 'Mode::'\n",
    "mode_columns = dmd.filter(like='Mode::')\n",
    "\n",
    "# Calculate the mean for each user_id, considering zeros\n",
    "mean_mode_per_user = mode_columns.groupby(dmd['user_id']).apply(lambda x: x.mean())\n",
    "mean_mode_per_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ebd886-4c1f-4e38-8708-3f9f47b7a74e",
   "metadata": {},
   "source": [
    "###  Get the sum distance per user in meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb83ea0-523f-4b43-a967-bd636893813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Filter columns that start with 'Mode::'\n",
    "mode_columns = dmd.filter(like='Mode::')\n",
    "\n",
    "# Calculate the mean for each user_id, considering zeros\n",
    "sum_mode_per_user = mode_columns.groupby(dmd['user_id']).apply(lambda x: x.sum())\n",
    "\n",
    "# Count the total entries grouped by user_id\n",
    "sum_mode_per_user['days_in_range_count'] = mode_columns.groupby(dmd['user_id']).size()\n",
    "\n",
    "sum_mode_per_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154edb98-4811-45b8-a6fb-d731574176d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stat = pd.read_csv('../Data/dumps_fors/UserStatistics.EPFL-Panel.2023-04-24--2023-06-05.csv', sep=';')\n",
    "stats = user_stat.loc[user_stat.IDNO.isin(usr),['IDNO','inactive_days_count','days_in_range_count']]\n",
    "\n",
    "sum_mode_per_user_ = pd.merge(sum_mode_per_user.reset_index(), stats, how='left', left_on='user_id', right_on='IDNO')\n",
    "del sum_mode_per_user_['IDNO']\n",
    "sum_mode_per_user_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be2f73-05dd-4de9-bea2-8cc525312c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_activity_stats(count_act):\n",
    "    # Convert 'started_at' column to datetime\n",
    "    count_act['started_at'] = pd.to_datetime(count_act['started_at'])\n",
    "\n",
    "    # Extract only the date part\n",
    "    count_act['date'] = count_act['started_at'].dt.date\n",
    "\n",
    "    # Group by 'user_id', then find the min and max dates\n",
    "    user_stats = count_act.groupby('user_id')['date'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "    # Calculate the total days in the range for each user\n",
    "    user_stats['days_in_range'] = (pd.to_datetime(user_stats['max']) - pd.to_datetime(user_stats['min'])).dt.days + 1\n",
    "\n",
    "    # Create a date range covering the entire date range for each user\n",
    "    date_ranges = user_stats.apply(lambda row: pd.date_range(row['min'], row['max'], freq='D'), axis=1)\n",
    "    user_stats['date_range'] = date_ranges\n",
    "\n",
    "   # Group by 'user_id' and count the unique dates\n",
    "    user_unique_dates = count_act.groupby(['user_id'])['date'].nunique().reset_index()\n",
    "\n",
    "    # Merge with user_unique_dates to get active_days_count\n",
    "    user_stats = pd.merge(user_stats, user_unique_dates, on='user_id', how='left')\n",
    "    user_stats.rename(columns={'date': 'active_days_count'}, inplace=True)\n",
    "\n",
    "    # Calculate the number of missing days within the range for each user\n",
    "    user_stats['missing_days'] = user_stats['days_in_range'] - user_stats['date_range'].apply(len)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    user_stats.drop(columns=['date_range'], inplace=True)\n",
    "\n",
    "    # Rename the min/may columns\n",
    "    user_stats.rename(columns={'min':'first_activity_date','max':'last_activity_date'}, inplace=True)\n",
    "\n",
    "    return user_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac245d-f9cf-46e4-81c8-a81c7bd7a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset of staypoints\n",
    "staypoints_ = staypoints.loc[staypoints.user_id.isin(usr),['user_id','started_at']]\n",
    "\n",
    "get_user_activity_stats(staypoints_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c816192-6f83-4fb0-9cc0-f535c28d9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = staypoints.loc[staypoints.user_id.isin(['CH2158']),['user_id','started_at']]\n",
    "test['date'] = test.started_at.dt.date\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0b8226-bf1d-4b87-9014-aabd11e81395",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test.date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ac896-0b7c-401d-a1da-d42890a37f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
