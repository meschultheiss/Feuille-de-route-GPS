{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166865c6-1177-4944-8846-280c5be42568",
   "metadata": {},
   "source": [
    "#  Module 1 : Parts modales\n",
    "\n",
    "**Description** : Le but de ce module est de mener un premier calcul des parts modales kilométriques i.e. les distances journalières moyennisées par mode et par motif.\n",
    "\n",
    "**Durée estimée première partie** : 7 jours\n",
    "\n",
    "**Objectifs spécifiques** :\n",
    "- [x] Sous-échantillonnage des résidents et visiteurs par canton (basé sur le GPS)\n",
    "- [x] Rééchantillonnage des jours d’observation pour avoir un calendrier continue par usager\n",
    "- [x] Intégrer le détail des transit\n",
    "- [x] Distinguer de façon aussi systématique que possible les jours sans déplacement des jours\n",
    "non-détectés et comparaison statistique au jours non-déplacé dans d’autres bases de\n",
    "données\n",
    "- [x] Recodage des modes selon besoin des cantons\n",
    "- [x] Calcul liminaire des parts modales kilométriques et par déplacements\n",
    "- [x] Ajout des données d’équipement (e.g. type de motorisation principale du ménage)\n",
    "- [ ] Documenter les hypothèses et limites du calcul liminaire des parts modales (e.g. aspects\n",
    "saisonniers, échantillonnage, perte de signal, moyennisation des données longitudinales, ...)\n",
    "\n",
    "**Résultats attendus** : Parts modales kilométriques par mode pour les résidents et visiteurs de chaque canton en vue du calcul des émissions carbone. Il doit être possible de calculer les parts modales en tenant compte des jours non-mobiles.\n",
    "\n",
    "**Sous-échantillonnage** :\n",
    "- Vaud : résident·es du canton + visiteur·euses\n",
    "- Genève : résident·es du canton + visiteur·euses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a82e2-45e5-4731-a524-7414b185cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db978265-9330-4054-9728-32b4d8ee4df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab3d72-e25d-4c20-9055-d0942219f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "from shapely import geometry, ops\n",
    "from shapely.geometry import MultiLineString, LineString, Point\n",
    "import os\n",
    "import concurrent.futures\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import JOIN_STYLE, Polygon, MultiPolygon\n",
    "\n",
    "import pycountry\n",
    "import xyt\n",
    "\n",
    "import time\n",
    "\n",
    "from panel_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf133b5-1d51-4369-ad6f-fd9681770f25",
   "metadata": {},
   "source": [
    "### Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5e056-eb6b-42fa-8e51-fe58296bc893",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Définir le CRS du projet (EPSG:4326 for WGS84)\n",
    "target_crs = 'EPSG:4326'\n",
    "print(\"CRS du projet: WGS84 \\n\")\n",
    "\n",
    "#Charger les étapes\n",
    "legs_ = pd.read_pickle('../Data/dumps_motiontag/storyline_time_space_filters/legs_filter.pkl')\n",
    "print(\"Fichier étape chargé\")\n",
    "\n",
    "#Charger les activités\n",
    "staypoints = pd.read_pickle('../Data/dumps_motiontag/storyline_formated/staypoints.pkl').reset_index(drop=True)\n",
    "print(\"Fichier activité chargé\")\n",
    "\n",
    "#Charger les user_statistics\n",
    "usr_stats = pd.read_pickle('../Data/processed_feuille_de_route/gps_user_statistics.pkl')\n",
    "print(\"Fichier statistiques utilisateur·ices chargé\")\n",
    "\n",
    "#Charger les trips\n",
    "trips = pd.read_csv('../Data/dumps_motiontag/Trips2023-04-01--2023-08-31.csv')\n",
    "print(\"Fichier des déplacements chargé\")\n",
    "\n",
    "#Charger les bases officielles pour le sous-échantillonage géographique https://opendata.swiss/de/dataset/vm-uvek-zones-2017/resource/29b98f2c-42f2-4e72-b8b1-a39500ed0ad0\n",
    "TAZ = gpd.read_file('../../Vague1/Verkehrszonen_Schweiz_NPVM_2017_shp/Verkehrszonen_Schweiz_NPVM_2017.shp')\n",
    "TAZ = TAZ[['ID_Agglo', 'N_Agglo', 'N_KT', 'ID_Gem', 'geometry']]\n",
    "TAZ = TAZ.to_crs(crs=target_crs)\n",
    "#repare anomalies\n",
    "TAZ['geometry'] = TAZ['geometry'].buffer(0)\n",
    "shp_KT = TAZ.dissolve(by='N_KT').reset_index()\n",
    "print(\"Fichier Zones de traffic chargé\")\n",
    "\n",
    "# Get world countries GeoDataFrame\n",
    "def get_world_countries():\n",
    "    world_countries = gpd.read_file('../Data/other_shp/countries/ne_110m_admin_0_countries.shp')\n",
    "    world_countries = world_countries[['SOVEREIGNT','geometry']]\n",
    "    return world_countries\n",
    "world_countries = get_world_countries()\n",
    "print(\"Fichier Map Monde chargé\")\n",
    "\n",
    "# Get perimetre panel GeoDataFrame\n",
    "perimetre_panel = gpd.read_file('../Data/other_shp/perimetre_panel/perimetre_panel_08.01.24.shp')\n",
    "perimetre_panel = perimetre_panel.to_crs(crs=target_crs)\n",
    "perimetre_panel = perimetre_panel[['COMM_ID','COMM_NAME','Typo_panel','geometry']]\n",
    "perimetre_panel['panel_area'] = 1\n",
    "\n",
    "perimetre_panel_full = perimetre_panel.dissolve().geometry.apply(lambda p: close_holes(p))\n",
    "perimetre_panel_full = gpd.GeoDataFrame(geometry=[perimetre_panel_full.iloc[0]], crs=target_crs)\n",
    "perimetre_panel_full['panel_area'] = 1\n",
    "print(\"Fichier Périmètre panel chargé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d515285-2412-4701-a6da-c381cb2f7304",
   "metadata": {},
   "source": [
    "#### Ne garder que les user_id dans user_stats\n",
    "L'utilisateur 'CH9872' est enlevée du fichier legs car il ne contient qu'une observation (une seule étape).\n",
    "Toutes les autres observaitions sont conservées (n = 2806)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1780ca-3196-4b40-8956-3f3f581e0ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs = legs_.loc[legs_.user_id_motiontag.isin(usr_stats.user_id_motiontag.unique())].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af6acc9-8bef-43b0-a92c-89d37b1a6736",
   "metadata": {},
   "source": [
    "#### Ajouter un ID par usager-jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f0f69-d616-4e3e-a961-9859e3378c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajouter le user_id_day\n",
    "legs.insert(1, 'legs_date',legs.started_at.dt.date)\n",
    "legs['legs_date'] = pd.to_datetime(legs['legs_date'])\n",
    "\n",
    "legs.insert(\n",
    "    1,\"user_id_day\",legs[\"user_id_fors\"]\n",
    "    + \"_\" \n",
    "    + legs.started_at.dt.year.astype(str)\n",
    "    + legs.started_at.dt.month.astype(str).str.zfill(2)\n",
    "    + legs.started_at.dt.day.astype(str).str.zfill(2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d252b4-cf3b-4ebd-8b98-d23bfd54bef5",
   "metadata": {},
   "source": [
    "#### Ajouter le *next activity_id* aux étapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6a864-2c19-4043-84ba-ccce74c2e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort 'points' and 'legs' by 'started_at' to ensure data is in chronological order\n",
    "staypoints.sort_values(by=['user_id_fors','started_at'], inplace=True, ignore_index=True)\n",
    "legs.sort_values(by=['user_id_fors','started_at'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2502247-2373-405d-a1b4-79e1e7726492",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d77638-12af-4bef-b1d8-be9b14798f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = staypoints.copy()\n",
    "result['finished_at'] = pd.to_datetime(result['finished_at'], format='%Y-%m-%d %H:%M:%S')\n",
    "result.sort_values(by=['user_id_fors','finished_at'], inplace=True)\n",
    "\n",
    "\n",
    "previous_leg = legs[['user_id_fors', 'finished_at', 'leg_id', 'mode']].rename(columns={'finished_at': 'started_at', 'leg_id': 'previous_leg_id', 'mode':'previous_mode'})\n",
    "previous_leg['started_at'] = pd.to_datetime(previous_leg['started_at'], format='%Y-%m-%d %H:%M:%S')\n",
    "previous_leg.sort_values(by=['user_id_fors','started_at'], inplace=True)\n",
    "previous_leg.dropna(inplace=True)\n",
    "\n",
    "#for user_id_fors in result.user_id_fors.unique():\n",
    "result = pd.merge(result, previous_leg, on=['user_id_fors','started_at'], how='left')\n",
    "\n",
    "\n",
    "# Merge 'staypoints' with 'legs' to find the next leg\n",
    "next_leg = legs[['user_id_fors', 'started_at', 'leg_id', 'mode']].rename(columns={'started_at': 'finished_at', 'leg_id': 'next_leg_id', 'mode':'next_mode'})\n",
    "next_leg['finished_at'] = pd.to_datetime(next_leg['finished_at'], format='%Y-%m-%d %H:%M:%S')\n",
    "next_leg.sort_values(by=['user_id_fors','finished_at'], inplace=True)\n",
    "next_leg.dropna(inplace=True)\n",
    "\n",
    "#for user_id_fors in result.user_id_fors.unique():\n",
    "result = pd.merge(result, next_leg, on=['user_id_fors','finished_at'], how='left')\n",
    "\n",
    "\n",
    "# Drop unnecessary columns from the result\n",
    "result.sort_values(by=['user_id_fors','started_at'], inplace=True)#.drop(['next_leg_started_at', 'past_leg_started_at'], axis=1, inplace=True)\n",
    "\n",
    "# \n",
    "staypoints = result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537e669-ccde-4047-8623-992970e43c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "staypoints.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c019c0-863c-4702-a277-20fa49eb05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs = pd.merge(legs, staypoints[['activity_id', 'previous_leg_id','purpose']],\n",
    "               left_on='leg_id', right_on='previous_leg_id', how='left')\n",
    "legs.rename(columns={'activity_id':'leading_stay_id','purpose':'leading_stay_purpose'}, inplace=True)\n",
    "del legs['previous_leg_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6942c1-cb26-40be-b61e-57c102ea73e7",
   "metadata": {},
   "source": [
    "###  Ajouter la durée et la longueur des étapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384b81b-c21a-4f7a-a1b8-86ed7ae2b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Add length in meters\n",
    "legs['length'] = legs.to_crs('EPSG:2056').length\n",
    "# Add the duration in seconds\n",
    "legs['duration'] = (legs['finished_at'] - legs['started_at']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20b595-0d40-446c-acd1-24efe889f816",
   "metadata": {},
   "source": [
    "### Extraire les aires géographiques et les sous-échantillons (Genève et Vaud)\n",
    "Nous utilisons les zones de traffic du Modèle Voyageur de l'ARE.\n",
    "\n",
    "We want to sample :\n",
    "- all the residents of Canton de Genève\n",
    "- all the activities that happen in Canton de Genève\n",
    "\n",
    "To do that we flag all destionation Kantons in the oclumns _leading_stay_id_in_KT_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71810a6e-feda-4b21-90de-a6b6b9b0d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#staypoints_ = staypoints.copy()\n",
    "#staypoints = staypoints_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc26b5-9a9d-4017-9518-bebe5b9facea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Perform spatial join of staypoints with world_countries\n",
    "staypoints = gpd.sjoin(staypoints, world_countries, how='left', predicate='within').rename(columns={'SOVEREIGNT':'activity_in_country'})\n",
    "\n",
    "# Fill NaN values in the 'country_name' column with 'Unknown'\n",
    "staypoints['activity_in_country'] = staypoints['activity_in_country'].fillna('Unknown')\n",
    "staypoints.drop(columns=['index_right'], inplace=True)\n",
    "\n",
    "# Perform spatial join with TAZ\n",
    "staypoints = gpd.sjoin(staypoints, TAZ[['N_KT', 'geometry']], how='left', predicate='within').rename(columns={'N_KT': 'activity_in_KT'})\n",
    "staypoints.drop(columns=['index_right'], inplace=True)\n",
    "# Adjust the saptial join for corner cases\n",
    "staypoints.loc[~staypoints.activity_in_KT.isna(),'activity_in_country'] = 'Switzerland'\n",
    "staypoints['activity_in_KT'] = staypoints['activity_in_KT'].fillna('Other')\n",
    "\n",
    "# Perform spatial join with Panel Lemanique area\n",
    "# Function to check if a point is within the panel's geometry\n",
    "staypoints = gpd.sjoin(staypoints, perimetre_panel_full.dissolve(), how='left', predicate='within')\n",
    "staypoints.loc[staypoints.panel_area.isna(),'panel_area'] = 0\n",
    "staypoints['panel_area'] = staypoints.panel_area.astype(int)\n",
    "staypoints.drop(columns=['index_right'], inplace=True)\n",
    "\n",
    "# Get the home and motorization of the user_\n",
    "staypoints = pd.merge(staypoints, usr_stats[['KT_home_survey','user_id_fors','car_in_HH_count','main_motor']], on='user_id_fors', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff7dfae-3f03-4055-817b-bcaf687d6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "legs = pd.merge(legs, staypoints[['activity_id','activity_in_KT','panel_area','KT_home_survey']].dropna(subset='activity_id'),\n",
    "                left_on='leading_stay_id',\n",
    "                right_on='activity_id',\n",
    "                how='left')\n",
    "del legs['activity_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfda598-1591-43a6-b50d-c83e0c85058a",
   "metadata": {},
   "source": [
    "#### Cartographie pour vérifier les filtres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa5949f-d993-4377-b57c-175ee4497b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "staypoints.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065b6d6e-3ec3-4bef-b451-5e0e7058f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "xyt.plot_gps(staypoints[staypoints.activity_in_KT == 'GE'].rename(columns={'user_id_fors':'user_id'}).dropna()[:2000], geo_columns='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc08ba-0aa6-4a7c-9501-5cb87bbd2751",
   "metadata": {},
   "source": [
    "#### Ajouter indicateur si valeur extrême"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619fa72-1d92-4c03-8d26-f510989f9bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(legs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db240296-b635-4d21-9940-f4177c7e03f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add quantile columns\n",
    "def add_quantile_flags(group, column_prefix):\n",
    "    quantile_95 = group['length_leg'].quantile(0.95)\n",
    "    quantile_98 = group['length_leg'].quantile(0.98)\n",
    "    quantile_99 = group['length_leg'].quantile(0.99)\n",
    "    group[f'extreme95_length_{column_prefix}'] = group['length_leg'] > quantile_95\n",
    "    group[f'extreme98_length_{column_prefix}'] = group['length_leg'] > quantile_98\n",
    "    group[f'extreme99_length_{column_prefix}'] = group['length_leg'] > quantile_99\n",
    "    return group\n",
    "\n",
    "# List of grouping columns\n",
    "grouping_columns = ['detected_mode', 'mode']\n",
    "\n",
    "# Loop through each grouping column\n",
    "for mode_col in grouping_columns:\n",
    "    # Create a copy of the relevant subset\n",
    "    quant_detected_mode = legs[['leg_id', mode_col, 'length_leg']].copy()\n",
    "    \n",
    "    # Initialize an empty list to collect results\n",
    "    dfs_to_concat = []\n",
    "    \n",
    "    # Loop through unique values of mode_col\n",
    "    for mode in quant_detected_mode[mode_col].unique():\n",
    "        # Filter dataframe for the current mode_col value\n",
    "        subset = 0\n",
    "        subset = quant_detected_mode[quant_detected_mode[mode_col] == mode].copy()\n",
    "        \n",
    "        # Apply quantile flags function\n",
    "        subset = add_quantile_flags(subset, mode_col)\n",
    "        \n",
    "        # Append to list\n",
    "        dfs_to_concat.append(subset)\n",
    "    \n",
    "    # Concatenate all dataframes in the list\n",
    "    concatenated_df = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "    \n",
    "    # Drop unnecessary columns before merge\n",
    "    drop_columns = ['length_leg', mode_col]\n",
    "    concatenated_df.drop(columns=drop_columns, inplace=True)\n",
    "    concatenated_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Merge concatenated_df back to legs based on leg_id\n",
    "    legs = pd.merge(legs,concatenated_df, on='leg_id', how='left').drop_duplicates(subset=['leg_id','mode','detected_mode','user_id_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84a5d9-a2e4-4df9-bd4b-49c0ed2d7d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(legs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35408da4-379b-4ce2-871d-04adb6133e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs.groupby('mode')['length_leg'].mean() / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86905817-bf17-4090-a1ce-13f96f03c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs[legs.extreme95_length_mode].groupby('mode')['length_leg'].mean() / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb68208-c3d7-4ccd-8007-f802e3954d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs[legs.extreme99_length_mode].groupby('mode')['length_leg'].mean() / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58cc41-6263-4873-ab22-0b14d6e04518",
   "metadata": {},
   "source": [
    "#### Arranger le fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542260d2-6de3-4cdb-a3e5-586dde60cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1480d76-57b9-4ab8-841c-371c1794650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 'usr_w_constant_bad_signal', length\n",
    "\n",
    "\n",
    "col_order = col = ['leg_id', 'user_id_day', 'user_id_fors', 'user_id_motiontag', 'type',\n",
    " 'geometry', 'legs_date', 'started_at', 'started_at_timezone', \n",
    " 'finished_at','finished_at_timezone', \n",
    " 'length_leg', 'detected_mode', 'mode', 'leading_stay_purpose',\n",
    " 'confirmed_at', 'started_on', 'misdetected_completely', 'merged',\n",
    " 'created_at', 'updated_at', 'started_at_in_timezone',\n",
    " 'finished_at_in_timezone', 'confirmed_at_in_timezone',\n",
    " 'created_at_in_timezone', 'updated_at_in_timezone',\n",
    " 'point_per_linestring', 'max_signlalloss_meters',\n",
    " 'rel_max_signalloss', 'low_quality_legs_1', 'low_quality_legs_2', 'leading_stay_id',\n",
    " 'duration', 'activity_in_KT', 'panel_area', 'KT_home_survey',\n",
    "    'extreme95_length_detected_mode',\n",
    "       'extreme98_length_detected_mode', 'extreme99_length_detected_mode',\n",
    "       'extreme95_length_mode', 'extreme98_length_mode',\n",
    "       'extreme99_length_mode']\n",
    "\n",
    "\n",
    "legs = legs[col_order].dropna(subset='user_id_fors')\n",
    "legs.rename(columns={'panel_area':'activity_in_panel_area'}, inplace=True)\n",
    "legs.sort_values(by=['user_id_fors','started_at'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf3554b-bbde-49f7-878d-24a94d1ed847",
   "metadata": {},
   "source": [
    "#### Exporter la données pour l'app streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c0f6b-4c6b-4beb-931a-7662c31f7ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output for streamlit app\n",
    "legs_nogeometry = legs.copy()\n",
    "del legs_nogeometry['geometry']\n",
    "del legs_nogeometry['user_id_motiontag']\n",
    "#legs_nogeometry.to_pickle('../Data/processed_feuille_de_route/legs_nogeometry.pkl')\n",
    "\n",
    "# And for other usages\n",
    "#legs.to_pickle('../Data/processed_feuille_de_route/legs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6b1f4-b56e-4f20-b15c-92762170ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(legs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a714d50-75a2-4e37-b4bb-50398a4d7c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d017944-a34b-4200-b554-4d067decd86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ea3d8-a433-49cb-b989-b51e6ce450a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706ff3a-329e-4aa6-9683-cf9a2d2284b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e95e3b-679c-4d9d-8202-5dea8ae79e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d491808-a5fe-4766-ba74-4331472c3c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51ed55-450d-4c9b-979a-c6b24437dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_daily_modal_distances(df):\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['length'] = df['length'].astype(float)\n",
    "    # Group by 'user_id_day', 'previous_mode', and 'previous_leg_id', then sum the distances\n",
    "    grouped = df.groupby(['user_id_fors', 'user_id_day', 'mode'])['length'].sum().reset_index()\n",
    "\n",
    "    # Pivot the table to have modes as columns\n",
    "    pivoted = grouped.pivot_table(\n",
    "        index=['user_id_fors', 'user_id_day'],\n",
    "        columns='mode',\n",
    "        values='length',\n",
    "        aggfunc='sum'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Resample to include missing days and fill NaNs with different values in different columns\n",
    "    pivoted['date'] = pd.to_datetime(pivoted['user_id_day'].str[-8:])\n",
    "    # Create a date range covering the entire date range for each ID\n",
    "    date_ranges = pivoted.groupby('user_id_fors')['date'].agg(['min', 'max']).reset_index()\n",
    "    date_ranges['legs_date'] = date_ranges.apply(lambda row: pd.date_range(row['min'], row['max'], freq='D'), axis=1)\n",
    "\n",
    "    # Create a Cartesian product of IDs and date ranges\n",
    "    cartesian = date_ranges.explode('legs_date').reset_index(drop=True)\n",
    "\n",
    "    # Complete the original df with a continuous timeline\n",
    "    pivoted_filled = pd.merge(pivoted, cartesian[['user_id_fors', 'legs_date']], how='outer', left_on=['user_id_fors', 'date'],\n",
    "                              right_on=['user_id_fors', 'legs_date'])\n",
    "\n",
    "    # Create 'days_without_track' column and mark as True for added rows, False otherwise\n",
    "    pivoted_filled['days_without_track'] = pivoted_filled['date'].isnull().astype(int)\n",
    "    del pivoted_filled['date']\n",
    "\n",
    "    # Fill missing values in the user_id_day column\n",
    "    pivoted_filled['user_id_day'] = pivoted_filled.apply(\n",
    "        lambda row: row['user_id_day'] if not pd.isnull(row['user_id_day'])\n",
    "        else row['user_id_fors'] + \"_\" +\n",
    "             row['legs_date'].strftime('%Y%m%d'),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Fill missing values in the modes columns\n",
    "    # Get the columns that start with 'Mode::'\n",
    "    modes_columns = [col for col in pivoted_filled.columns if col.startswith('Mode::')]\n",
    "\n",
    "    # Fill missing values in the 'modes_columns' with 0\n",
    "    pivoted_filled[modes_columns] = pivoted_filled[modes_columns].fillna(0)\n",
    "\n",
    "    # Sort the resulting DataFrame\n",
    "    pivoted_filled.sort_values(by=['user_id_fors', 'legs_date'], inplace=True)\n",
    "\n",
    "    return pivoted_filled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d33200-5566-4924-b6d9-dea162060c1e",
   "metadata": {},
   "source": [
    "#### Fonctions pour l'app streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f004b1-73ed-4d44-a987-23bd35ddbf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "from shapely import geometry, ops\n",
    "from shapely.geometry import MultiLineString, LineString, Point\n",
    "import os\n",
    "import concurrent.futures\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import JOIN_STYLE, Polygon, MultiPolygon\n",
    "\n",
    "import pycountry\n",
    "import xyt\n",
    "\n",
    "import time\n",
    "\n",
    "from panel_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "643a3627-60f9-45d6-98aa-6753270158a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_nogeometry = pd.read_pickle('../Streamlit/data/legs_nogeometry.pkl')\n",
    "usr_stats = pd.read_pickle('../Streamlit/data/usr_stats_nogeometry.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b56724-baa3-4d82-aaa2-fc88a1d39115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET PARAMETERS\n",
    "\n",
    "#KT = st.sidebar.selectbox('**Sélectionner le canton pour échantillonnage**', ['GE', 'VD', 'Tous'])\n",
    "#weight = st.sidebar.selectbox('**Sélectionner la pondération**', ['wgt_cant_trim_gps', 'Aucun']) #,'wgt_agg_trim_gps'\n",
    "#period_of_tracking = st.sidebar.selectbox(\"**Sélectionner la période d'observation à considérer\\*\\***\", ['active_days_count', 'days_with_track','days_in_range'])\n",
    "#\n",
    "#mode_aggreg = st.sidebar.selectbox(\"**Sélectionner le niveau d'aggrégation des modes**\", \n",
    "#                                   [\"Motiontag\", \"MRMT\", \"Niveau 1\", \"Niveau 2\"])\n",
    "#\n",
    "#bad_users= st.sidebar.checkbox('Inclure les utilisateurs avec mauvais signal récurrent', value=False)\n",
    "#visitors = st.sidebar.checkbox('Inclure les visiteurs', value=False)\n",
    "#airplane = st.sidebar.checkbox('Inclure les étapes en avion', value=False)\n",
    "#incl_signal_loss = st.sidebar.checkbox('Inclure les étapes avec une perte de signal importante (recommandé)', value=True)\n",
    "#outliers = st.sidebar.selectbox('**Exclure les distances extrêmes**', ['Quantile95', 'Quantile98', 'Quantile99', 'Aucune'], index=2)\n",
    "#mode_col = st.sidebar.selectbox(\"**Sélectionner la colonne des modes de transport**\", ['detected_mode', 'mode'])\n",
    "\n",
    "mode_col = 'detected_mode'\n",
    "\n",
    "bad_users = False\n",
    "period_of_tracking = 'days_in_range'\n",
    "\n",
    "airplane = False\n",
    "KT = 'GE'\n",
    "visitors = False\n",
    "\n",
    "incl_signal_loss = 'Non'\n",
    "\n",
    "\n",
    "weight = 'wgt_cant_trim_gps'\n",
    "\n",
    "outliers = 'Aucune'\n",
    "\n",
    "mode_aggreg = 'Motiontag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c730ed7-a71c-48ec-9cd6-55df5a1e007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBSET USERS\n",
    "\n",
    "# Filter on bad users\n",
    "bad_users_condition = (usr_stats['usr_w_constant_bad_signal'] == 0) if not bad_users else np.full(len(usr_stats), True)\n",
    "\n",
    "usr_stats_sub_list = usr_stats.loc[bad_users_condition, 'user_id_fors'].to_list()\n",
    "\n",
    "# Creating a dictionary mapping user IDs to their corresponding period of tracking values\n",
    "active_days_mapping = usr_stats.set_index('user_id_fors').loc[usr_stats_sub_list, period_of_tracking].to_dict()\n",
    "\n",
    "# Creating a dictionary mapping user IDs to their corresponding weight values\n",
    "# If weight is 'Aucun', map each user ID to the value 1\n",
    "if weight == 'Aucun':\n",
    "    weight_mapping = usr_stats.set_index('user_id_fors').loc[usr_stats_sub_list].apply(lambda x: 1, axis=1).to_dict()\n",
    "else:\n",
    "    weight_mapping = usr_stats.set_index('user_id_fors').loc[usr_stats_sub_list, weight].to_dict()\n",
    "\n",
    "# SUBSET LEGS\n",
    "legs_sub = legs_nogeometry[legs_nogeometry.user_id_fors.isin(usr_stats_sub_list)].copy()\n",
    "\n",
    "# Filter Airplane if needed\n",
    "airplane_condition = (legs_sub[mode_col] != 'Mode::Airplane') if not airplane else np.full(len(legs_sub), True)\n",
    "\n",
    "\n",
    "# Filter on residents and visitors\n",
    "resid_condition = (legs_sub['KT_home_survey'] == KT) if KT != 'Tous' else np.full(len(legs_sub), True)\n",
    "visit_condition = (legs_sub['activity_in_KT'] == KT) if visitors else np.full(len(legs_sub), True)\n",
    "if visitors:\n",
    "    resident_visit_condition = resid_condition | visit_condition\n",
    "else:\n",
    "    resident_visit_condition = resid_condition\n",
    "\n",
    "# Filter tracks with signal loss\n",
    "# Handle selection\n",
    "if incl_signal_loss == \"0.05 de perte\":\n",
    "    signal_loss_threshold = 'low_quality_legs_1'\n",
    "elif incl_signal_loss == \"0.07 de perte\":\n",
    "    signal_loss_threshold = 'low_quality_legs_2'\n",
    "signal_loss_condition = (legs_sub[signal_loss_threshold] == 0) if incl_signal_loss != \"Non\" else np.full(len(legs_sub), True)\n",
    "\n",
    "# Filter outliers if needed\n",
    "# Handle selection\n",
    "if outliers == \"Quantile95\":\n",
    "    outlier_threshold = f\"extreme95_length_{mode_col}\"\n",
    "elif outliers == \"Quantile98\":\n",
    "    outlier_threshold = f\"extreme98_length_{mode_col}\"\n",
    "elif outliers == \"Quantile99\":\n",
    "    outlier_threshold = f\"extreme99_length_{mode_col}\"\n",
    "\n",
    "outliers_condition = (~legs_sub[outlier_threshold]) if outliers != \"Aucune\" else np.full(len(legs_sub), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67979dc9-3f4e-4c71-93d0-822deb689fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dmd_condition = airplane_condition & resident_visit_condition & signal_loss_condition & outliers_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "964684e7-fb9d-4732-9e2d-65de9577823b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b26331e-a088-4484-8afb-a0daa972db5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1         True\n",
       "2         True\n",
       "3         True\n",
       "4         True\n",
       "          ... \n",
       "669272    True\n",
       "669273    True\n",
       "669274    True\n",
       "669275    True\n",
       "669276    True\n",
       "Name: extreme95_length_detected_mode, Length: 661273, dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666f5f1-bedc-4267-b4fd-8c484d7ab136",
   "metadata": {},
   "outputs": [],
   "source": [
    "resident_visit_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf9246-ff7d-4db7-804d-a48ffdb9e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(signal_loss_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2c9ba6-d3e2-4594-8801-61d1fef489e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "airplane_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee4df4-e917-49cc-b817-2346bd897f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d3a05-6442-47c8-9bea-48642ce71262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a80ab-e41f-41fc-84dc-5c4235644a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894777ad-3d5f-4599-9411-69e1b37ed9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_condition=legs_sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f4080-5cad-49f9-b37d-139e74fe3e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb9b9f-790f-4eff-b6f9-36ea150b8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_sub[mode_col] != 'Mode::Airplane' if not airplane else np.full(len(legs_sub), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a6965-0a7a-4d31-83b6-37d6e30e4099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f05b71-66f2-4ab9-8ba9-41baaca12651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352fd447-5697-4e81-8216-395f4cfeed8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e032b2d4-d227-449d-bedc-a6906002c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(legs_nogeometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479bbb85-d6d3-4aea-ba47-1a6b698ffc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute daily modal distances\n",
    "def get_daily_modal_distances(df, mode_col):\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['length_leg'] = df['length_leg'].astype(float)\n",
    "    # Group by 'user_id_day', 'previous_mode', and 'previous_leg_id', then sum the distances\n",
    "    grouped = df.groupby(['user_id_fors', 'user_id_day', mode_col])['length_leg'].sum().reset_index()\n",
    "\n",
    "    # Pivot the table to have modes as columns\n",
    "    pivoted = grouped.pivot_table(\n",
    "        index=['user_id_fors', 'user_id_day'],\n",
    "        columns=mode_col,\n",
    "        values='length_leg',\n",
    "        aggfunc='sum'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Resample to include missing days and fill NaNs with different values in different columns\n",
    "    pivoted['date'] = pd.to_datetime(pivoted['user_id_day'].str[-8:])\n",
    "    # Create a date range covering the entire date range for each ID\n",
    "    date_ranges = pivoted.groupby('user_id_fors')['date'].agg(['min', 'max']).reset_index()\n",
    "    date_ranges['legs_date'] = date_ranges.apply(lambda row: pd.date_range(row['min'], row['max'], freq='D'), axis=1)\n",
    "\n",
    "    # Create a Cartesian product of IDs and date ranges\n",
    "    cartesian = date_ranges.explode('legs_date').reset_index(drop=True)\n",
    "\n",
    "    # Complete the original df with a continuous timeline\n",
    "    pivoted_filled = pd.merge(pivoted, cartesian[['user_id_fors', 'legs_date']], how='outer', left_on=['user_id_fors', 'date'],\n",
    "                              right_on=['user_id_fors', 'legs_date'])\n",
    "\n",
    "    # Create 'days_without_track' column and mark as True for added rows, False otherwise\n",
    "    pivoted_filled['days_without_track'] = pivoted_filled['date'].isnull().astype(int)\n",
    "    del pivoted_filled['date']\n",
    "\n",
    "    # Fill missing values in the user_id_day column\n",
    "    pivoted_filled['user_id_day'] = pivoted_filled.apply(\n",
    "        lambda row: row['user_id_day'] if not pd.isnull(row['user_id_day'])\n",
    "        else row['user_id_fors'] + \"_\" +\n",
    "             row['legs_date'].strftime('%Y%m%d'),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Fill missing values in the modes columns\n",
    "    # Get the columns that start with 'Mode::'\n",
    "    modes_columns = [col for col in pivoted_filled.columns if col.startswith('Mode::')]\n",
    "\n",
    "    # Fill missing values in the 'modes_columns' with 0\n",
    "    pivoted_filled[modes_columns] = pivoted_filled[modes_columns].fillna(0)\n",
    "\n",
    "    # Sort the resulting DataFrame\n",
    "    pivoted_filled.sort_values(by=['user_id_fors', 'legs_date'], inplace=True)\n",
    "\n",
    "    return pivoted_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b22b4-0f7e-40b9-ac5c-33543bbb9fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute daily modal distances\n",
    "def calculate_dmd(legs_nogeom, usr_stats, KT, weight, period_of_tracking, bad_users, visitors, airplane, incl_signal_loss, outliers, mode_col):\n",
    "\n",
    "    # SUBSET USERS\n",
    "    \n",
    "    # Filter on bad users\n",
    "    bad_users_condition = (usr_stats['usr_w_constant_bad_signal'] == 0) if not bad_users else np.full(len(usr_stats), True)\n",
    "    \n",
    "    usr_stats_sub_list = usr_stats.loc[bad_users_condition, 'user_id_fors'].to_list()\n",
    "    \n",
    "    # Creating a dictionary mapping user IDs to their corresponding period of tracking values\n",
    "    active_days_mapping = usr_stats.set_index('user_id_fors').loc[usr_stats_sub_list, period_of_tracking].to_dict()\n",
    "    \n",
    "    # Creating a dictionary mapping user IDs to their corresponding weight values\n",
    "    # If weight is 'Aucun', map each user ID to the value 1\n",
    "    if weight == 'Aucun':\n",
    "        weight_mapping = usr_stats.set_index('user_id_fors').loc[usr_stats_sub_list].apply(lambda x: 1, axis=1).to_dict()\n",
    "    else:\n",
    "        weight_mapping = usr_stats.set_index('user_id_fors').loc[usr_stats_sub_list, weight].to_dict()\n",
    "    \n",
    "    # SUBSET LEGS\n",
    "    legs_sub = legs_nogeom[legs_nogeom.user_id_fors.isin(usr_stats_sub_list)].copy()\n",
    "    \n",
    "    # Filter Airplane if needed\n",
    "    airplane_condition = (legs_sub[mode_col] != 'Mode::Airplane') if not airplane else np.full(len(legs_sub), True)\n",
    "    \n",
    "    \n",
    "    # Filter on residents and visitors\n",
    "    resid_condition = (legs_sub['KT_home_survey'] == KT) if KT != 'Tous' else np.full(len(legs_sub), True)\n",
    "    visit_condition = (legs_sub['activity_in_KT'] == KT) if visitors else np.full(len(legs_sub), True)\n",
    "    if visitors:\n",
    "        resident_visit_condition = resid_condition | visit_condition\n",
    "    else:\n",
    "        resident_visit_condition = resid_condition\n",
    "    \n",
    "    # Filter tracks with signal loss\n",
    "    # Handle selection\n",
    "    if incl_signal_loss == \"0.05 de perte\":\n",
    "        signal_loss_threshold = 'low_quality_legs_1'\n",
    "    elif incl_signal_loss == \"0.07 de perte\":\n",
    "        signal_loss_threshold = 'low_quality_legs_2'\n",
    "    signal_loss_condition = (legs_sub[signal_loss_threshold] == 0) if incl_signal_loss != \"Non\" else pd.Series(np.full(len(legs_sub), True))\n",
    "    \n",
    "    # Filter outliers if needed\n",
    "    # Handle selection\n",
    "    if outliers == \"Quantile95\":\n",
    "        outlier_threshold = f\"extreme95_length_{mode_col}\"\n",
    "    elif outliers == \"Quantile98\":\n",
    "        outlier_threshold = f\"extreme98_length_{mode_col}\"\n",
    "    elif outliers == \"Quantile99\":\n",
    "        outlier_threshold = f\"extreme99_length_{mode_col}\"\n",
    "    \n",
    "    outliers_condition = (~legs_sub[outlier_threshold]) if outliers != \"Aucune\" else np.full(len(legs_sub), True)\n",
    "    \n",
    "    # Combine all conditions\n",
    "    def check_boolean_series(condition, name):\n",
    "        if not isinstance(condition, pd.Series) or condition.dtype != 'bool':\n",
    "            raise ValueError(f\"{name} is not a boolean series.\")\n",
    "    \n",
    "    check_boolean_series(airplane_condition, 'airplane_condition')\n",
    "    check_boolean_series(resident_visit_condition, 'resident_visit_condition')\n",
    "    check_boolean_series(signal_loss_condition, 'signal_loss_condition')\n",
    "    check_boolean_series(outliers_condition, 'outliers_condition')\n",
    "    \n",
    "    combined_dmd_condition = airplane_condition & resident_visit_condition & signal_loss_condition & outliers_condition\n",
    "    \n",
    "    dmd = get_daily_modal_distances(legs_sub[combined_dmd_condition], mode_col)\n",
    "    \n",
    "    # Filtering columns that start with 'Mode::' for further calculations\n",
    "    mode_columns = dmd.filter(like='Mode::')\n",
    "    \n",
    "    # Calculating the sum for each 'Mode::' column for each user_id\n",
    "    sum_mode_per_user = mode_columns.groupby(dmd['user_id_fors']).apply(lambda x: x.sum())\n",
    "    \n",
    "    # Weighting the sum of each 'Mode::' column based on user weights and active days\n",
    "    sum_mode_per_user_w = sum_mode_per_user.mul(sum_mode_per_user.index.map(weight_mapping), axis=0).div(sum_mode_per_user.index.map(active_days_mapping), axis=0).dropna()\n",
    "\n",
    "    return sum_mode_per_user_w.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336eb697-8746-4566-b7ff-d5590f91052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate modes in dmd\n",
    "def dmd_aggreg_modes(dmd, level):\n",
    "    df = dmd.copy()\n",
    "\n",
    "    if level == \"Motiontag\":\n",
    "        return df\n",
    "    else:\n",
    "        if level == \"MRMT\":\n",
    "            # First level of mode mapping\n",
    "            mode_mapping = {\n",
    "                'Voiture conducteur': ['Mode::Car', 'Mode::Carsharing','Mode::Ecar'],\n",
    "                'Taxi': ['Mode::TaxiUber'],\n",
    "                '2RM': ['Mode::KickScooter','Mode::Motorbike'],\n",
    "                'Train': ['Mode::RegionalTrain','Mode::Train'],\n",
    "                'Bus': ['Mode::Bus'],\n",
    "                'Tram/Métro': ['Mode::LightRail','Mode::Subway','Mode::Tram'],\n",
    "                'Bateau': ['Mode::Boat'],\n",
    "                'Marche': ['Mode::Walk'],\n",
    "                'Vélo conventionnel': ['Mode::Bicycle', 'Mode::Bikesharing'],\n",
    "                'Vélo électrique': ['Mode::Ebicycle'],\n",
    "                'Engins assimilés à des véhicules': ['Mode::Other'],\n",
    "                'Avion': ['Mode::Airplane']\n",
    "            }\n",
    "    \n",
    "        elif level == \"Niveau 1\":\n",
    "            # Second level of mode mapping\n",
    "            mode_mapping = {\n",
    "                'Voiture': ['Mode::Car', 'Mode::Carsharing','Mode::Ecar','Mode::TaxiUber'],\n",
    "                '2RM': ['Mode::KickScooter', 'Mode::Motorbike'],\n",
    "                'Train': ['Mode::Train','Mode::RegionalTrain'],\n",
    "                'Autre TP': ['Mode::Bus','Mode::LightRail','Mode::Subway','Mode::Tram','Mode::Boat'],\n",
    "                'Marche': ['Mode::Walk'],\n",
    "                'Vélo': ['Mode::Bicycle', 'Mode::Bikesharing','Mode::Ebicycle'],\n",
    "                'Autre': ['Mode::Other'],\n",
    "                'Avion': ['Mode::Airplane']\n",
    "            }\n",
    "    \n",
    "        elif level == \"Niveau 2\":\n",
    "            # Third level of mode mapping\n",
    "            mode_mapping = {\n",
    "                'TIM': ['Mode::Car', 'Mode::Carsharing','Mode::Ecar', 'Mode::KickScooter','Mode::Motorbike','Mode::TaxiUber'],\n",
    "                'TP': ['Mode::Boat','Mode::Bus','Mode::LightRail','Mode::RegionalTrain', 'Mode::Subway','Mode::Train', 'Mode::Tram'],\n",
    "                'MD': ['Mode::Bicycle', 'Mode::Bikesharing','Mode::Ebicycle', 'Mode::Walk'],\n",
    "                'Avion': ['Mode::Airplane'],\n",
    "                'Autre': ['Mode::Other']\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Invalid level. Please choose Motiontag, MRMT, Niveau 1 or Niveau 2 for the desired level.\")\n",
    "        \n",
    "        # Create new columns based on the mapping\n",
    "        for new_column, modes in mode_mapping.items():\n",
    "            # Check if modes exist in columns before summing\n",
    "            valid_modes = [mode for mode in modes if mode in df.columns]\n",
    "            df[new_column] = df[valid_modes].sum(axis=1, min_count=1)\n",
    "        \n",
    "        # Create a new DataFrame with the new columns\n",
    "        new_dmd = df[list(mode_mapping.keys())].copy()\n",
    "        \n",
    "        # Check if 'Avion' column is full of NaN, then drop it\n",
    "        if 'Avion' in new_dmd.columns and new_dmd['Avion'].isnull().all():\n",
    "            new_dmd.drop(columns=['Avion'], inplace=True)\n",
    "    \n",
    "        return new_dmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebb109-291d-4650-a9b4-e647e830bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmd_w = calculate_dmd(legs_nogeometry, usr_stats, KT, weight, period_of_tracking, bad_users, visitors, airplane, incl_signal_loss, outliers, mode_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5a00d-03c5-4f7a-b060-3f9d4071a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmd_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfefa5-b3c6-4f7a-a159-1ed226e6597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def dmd_aggreg_modes(dmd, level):\n",
    "    df = dmd.copy()\n",
    "\n",
    "    if level == \"Motiontag\":\n",
    "        return df\n",
    "    else:\n",
    "        if level == \"MRMT\":\n",
    "            # First level of mode mapping\n",
    "            mode_mapping = {\n",
    "                'Voiture conducteur': ['Mode::Car', 'Mode::Carsharing','Mode::Ecar'],\n",
    "                'Taxi': ['Mode::TaxiUber'],\n",
    "                '2RM': ['Mode::KickScooter','Mode::Motorbike'],\n",
    "                'Train': ['Mode::RegionalTrain','Mode::Train'],\n",
    "                'Bus': ['Mode::Bus'],\n",
    "                'Tram/Métro': ['Mode::LightRail','Mode::Subway','Mode::Tram'],\n",
    "                'Bateau': ['Mode::Boat'],\n",
    "                'Marche': ['Mode::Walk'],\n",
    "                'Vélo conventionnel': ['Mode::Bicycle', 'Mode::Bikesharing'],\n",
    "                'Vélo électrique': ['Mode::Ebicycle'],\n",
    "                'Engins assimilés à des véhicules': ['Mode::Other'],\n",
    "                'Avion': ['Mode::Airplane']\n",
    "            }\n",
    "    \n",
    "        elif level == \"Niveau 1\":\n",
    "            # Second level of mode mapping\n",
    "            mode_mapping = {\n",
    "                'Voiture conducteur': ['Mode::Car', 'Mode::Carsharing','Mode::Ecar','Mode::TaxiUber'],\n",
    "                '2RM': ['Mode::KickScooter', 'Mode::Motorbike'],\n",
    "                'Train': ['Mode::Train','Mode::RegionalTrain'],\n",
    "                'Autre TP': ['Mode::Bus','Mode::LightRail','Mode::Subway','Mode::Tram','Mode::Boat'],\n",
    "                'Marche': ['Mode::Walk'],\n",
    "                'Vélo': ['Mode::Bicycle', 'Mode::Bikesharing','Mode::Ebicycle'],\n",
    "                'Autre': ['Mode::Other'],\n",
    "                'Avion': ['Mode::Airplane']\n",
    "            }\n",
    "    \n",
    "        elif level == \"Niveau 2\":\n",
    "            # Third level of mode mapping\n",
    "            mode_mapping = {\n",
    "                'TIM': ['Mode::Car', 'Mode::Carsharing','Mode::Ecar', 'Mode::KickScooter','Mode::Motorbike','Mode::TaxiUber'],\n",
    "                'TP': ['Mode::Boat','Mode::Bus','Mode::LightRail','Mode::RegionalTrain', 'Mode::Subway','Mode::Train', 'Mode::Tram'],\n",
    "                'MD': ['Mode::Bicycle', 'Mode::Bikesharing','Mode::Ebicycle', 'Mode::Walk'],\n",
    "                'Avion': ['Mode::Airplane'],\n",
    "                'Autre': ['Mode::Other']\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Invalid level. Please choose Motiontag, MRMT, Niveau 1 or Niveau 2 for the desired level.\")\n",
    "        \n",
    "        # Create new columns based on the mapping\n",
    "        for new_column, modes in mode_mapping.items():\n",
    "            # Check if modes exist in columns before summing\n",
    "            valid_modes = [mode for mode in modes if mode in df.columns]\n",
    "            df[new_column] = df[valid_modes].sum(axis=1, min_count=1)\n",
    "        \n",
    "        # Create a new DataFrame with the new columns\n",
    "        new_dmd = df[list(mode_mapping.keys())].copy()\n",
    "        \n",
    "        # Check if 'Avion' column is full of NaN, then drop it\n",
    "        if 'Avion' in new_dmd.columns and new_dmd['Avion'].isnull().all():\n",
    "            new_dmd.drop(columns=['Avion'], inplace=True)\n",
    "    \n",
    "        return new_dmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ac963-dde2-4740-9311-933d95f142cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223686c9-3de4-4786-ad93-b2be44643ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa4e77-ed57-4cb4-8383-e28d7f9fbeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f89bfc-ffda-4139-904c-7801063e9c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a247935-3f36-44a2-986f-2feeb1fd4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible values: 'GE', 'VD', 'Tous'\n",
    "KT = 'Tous'\n",
    "# Possible values: 'wgt_agg_trim_gps', 'wgt_cant_gps', 'wgt_agg_gps', 'wgt_cant_trim_gps', 'Aucun'\n",
    "weight = 'wgt_agg_trim_gps' \n",
    "\n",
    "# Selecting the period of tracking for user activities\n",
    "# Possible values: 'active_days_count', 'days_with_track'\n",
    "period_of_tracking = 'active_days_count'\n",
    "\n",
    "visitors = False\n",
    "airplane = False\n",
    "incl_signal_loss = True\n",
    "dmd, active = calculate_dmd(legs_nogeometry, usr_stats, KT, weight, \n",
    "              period_of_tracking, visitors, airplane,incl_signal_loss)\n",
    "\n",
    "dmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1564e9d0-72f4-4c08-9675-194d03cec9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_user_id_day = dmd_aggreg_modes(dmd, level='Niveau 1')\n",
    "dist_user_id_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b2da3-f45b-42fb-b86c-e5f14d612645",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs_nogeometry_lql = legs_nogeometry[legs_nogeometry.low_quality_legs_1 == 1].copy().reset_index(drop=True)\n",
    "dmd_lql = calculate_dmd(legs_nogeometry_lql, usr_stats, KT, weight, \n",
    "              period_of_tracking, visitors, airplane,incl_signal_loss)\n",
    "\n",
    "dist_user_id_day_lql = dmd_aggreg_modes(dmd_lql, level='Niveau 1')\n",
    "dist_user_id_day_lql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35434795-7c83-4e44-84cb-58511bd28043",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_user_id_day_lql.sum() / dist_user_id_day.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c8cab-3cea-4ea7-a2dc-34a9046a4d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_user_id_day_lql.sum().sum() / dist_user_id_day.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186faaf4-f013-4c50-b070-850c03cccc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dist_user_id_day_lql / dist_user_id_day).fillna(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60eab9-dbd2-4483-9b1e-42a753259988",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(legs_nogeometry[legs_nogeometry.low_quality_legs_1 == 1]) / len(legs_nogeometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b91b943-8d10-4c63-906c-71fe8bbfc185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760bf3b4-0d6c-46de-8585-9e753be8e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mode_per_user_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94326db3-44f2-4c4a-87eb-2b56dc586a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sum_mode_per_user_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef438526-5238-4fee-afa1-41aea7b2b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "modal_share = pd.DataFrame(sum_mode_per_user.sum()) #/ len(sum_mode_per_user))/ sum_mode_per_user.sum().sum() *100 \n",
    "modal_share.astype(int).rename(columns={0:'Distance_cumulée_metre'}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada21e4-e787-4652-a0fa-0c1bf025d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting a Pie Chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "mode_means = sum_mode_per_user_w.sum() / sum_mode_per_user_w.sum().sum()\n",
    "plt.pie(mode_means, labels=mode_means.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Modal Shares')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d339d3ae-9004-4251-90f1-bb4473020af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9631f27-291f-4aa2-b286-cf2a545b24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs.started_at.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c6fb0-9c1f-41f2-8697-3fa107e2b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "legs.started_at.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608066c8-f35f-4470-990f-47ffd4c70433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66edc0cc-d999-4932-babc-e2e5d42733c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f8c4bc-e8d0-42ed-a4f0-592108cd706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot the polygons with no background, grey lines\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot the polygons\n",
    "perimetre_panel.plot(ax=ax, facecolor='none', linewidth=1)\n",
    "\n",
    "# Remove axes\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a963cc-a42d-4399-9721-169553a134ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot to a PNG file\n",
    "output_file = \"../Data/temp_files/contour_panel.png\"\n",
    "plt.savefig(output_file, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a242f-fe74-44c9-85b2-2b8f90792199",
   "metadata": {},
   "outputs": [],
   "source": [
    "perimetre_panel#.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bb4d1-90a6-4eb1-8ce6-076154a2cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b9c48-69e1-4510-bc3a-3ad1281f2724",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAZ[TAZ.N_KT=='VD'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a2d91e-94ab-4004-a07b-2d4520bb028b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1b8f3-feeb-494f-a245-b033b914bf51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df27c5-88b8-4a2c-a2c1-2e67e2eaeecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
